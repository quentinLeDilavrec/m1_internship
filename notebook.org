#+TITLE: Comparing test and production behavior for dynamic languages
#+SUBTITLE: Internship at KTH from May 13, 2019 to July 15, 2019
#+AUTHOR: Quentin Le Dilavrec\inst{1}, supervised by Benoit Baudry\inst{2}
#+LaTeX_CLASS: llncs
# #+LaTeX_CLASS_OPTIONS: [runningheads]
#+OPTIONS: title:t toc:nil
#+LANGUAGE: american
#+EMAIL:     (concat "quentin.le-dilavrec" at-sign "ens-rennes.fr")
#+SEQ_TODO: APPT(a) TODO(t) NEXT(n) STARTED(s) WAITING(w) HALF(h) APPT(a) | DONE(d) CANCELLED(c) DEFERRED(f)
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="org.css"/>
#+LATEX_HEADER: \usepackage{titletoc}
#+LATEX_HEADER: \usepackage[utf8]{inputenc}
#+LATEX_HEADER: \usepackage[T1]{fontenc}
#+LATEX_HEADER: \usepackage{graphicx}
#+LATEX_HEADER: \usepackage{relsize}
#+LATEX_HEADER: \usepackage{tikz}
# #+LATEX_HEADER: \renewcommand\UrlFont{\color{blue}\rmfamily}
#+LATEX_HEADER: \usepackage[american]{babel}
#+LATEX_HEADER: \usepackage{minted}
#+LATEX_HEADER: \usepackage{mdframed}
#+LATEX_HEADER: \usepackage{color}
# #+LATEX_HEADER: \usepackage[a-1b]{pdfx}
# #+LATEX_HEADER: \usepackage{hyperref}
#+LATEX_HEADER: \usepackage[normalem]{ulem}
#+LATEX_HEADER: \tikzset{every picture/.style={line width=0.75pt}} %set default line width to 0.75pt        
# #+LATEX_HEADER: \institute{\inst{1} Affil1 \and \inst{2} Affil2 \and \inst{3} Affil3}
 # \inst{2} \and Author3 \inst{3}}
#+MACRO: color @@latex:{\color{$1}@@$2@@latex:}@@
# #+LATEX_HEADER: \def\email#1{\texttt{#1}}
#+LATEX_HEADER: \institute{ Univ. Rennes \email{Quentin.Le-dilavrec@ens-rennes.fr} \and KTH \email{baudry@kth.se}}

#+LATEX_HEADER: \usepackage{subfig}

# #+LATEX_HEADER: \usepackage{showframe}


# #+Begin_export latex
# \author{Author1 \and Author2}
# \maketitle
# #+END_EXPORT

#+BEGIN_abstract
Wordpress is the most popular Content Manager System. It is Open-Source and
power more than 34 percent of all websites.
Any improvement of the quality of a system like WordPress can have a great impact, 
be it on developers, website creators or end-users.
Like other web-applications, WordPress is increasing its usage of the client-side.
All those web-apps rely on JavaScript, which dynamic nature allows great flexibility
but challenges previous methods of instrumentation, analysis, and visualization.
#+END_abstract

* Introduction
# {{{color(red, some other numbers?)}}}
Wordpress is the most popular Content Manager System.
It is Open-Source and power more than 34 percent of all websites cite:w3techs_cms.
The official repository contains approximately 47,000 plugins, cumulating 600 million downloads cite:cabot2018wordpress,
and there is an entire economy based on these plugins.
So any improvement of the quality of a system like WordPress can have a great impact, 
be it on developers, website creators or end-users.
In web-applications, increased usage of the front-end can have many advantages,
it can off-load servers, provide more dynamic features, such as markdown.
But integrating new languages and new compilation pipelines
to a project as big as WordPress is not trivial.

Since a few years, the WordPress project has seen its proportion of javascript 
quickly increase especially for the front-end part cite:cabot2018wordpress under the name Gutenberg.
JavaScript is the programming language of the web,
it runs on almost all devices through web browsers,
and took the web thanks to his flexibility and accessibility.
It is multi-paradigm and its dynamic nature allows anyone to fiddle
with the behavior of any websites.
Moreover, it evolves swiftly and not with any frictions,
with a new version of the ECMAScript specification published almost every years,
followed by major companies or foundations that try to implement new features in their respective web browsers.
It makes projects that revolves around transcompilation the most popular and widespread javascript software,
they mainly focus on compatibility
between versions of the ECMAScript specification and the different web browsers
but they also allow developers to add their own features to the language and try to push the language forward.

But the dynamic nature of vanilla JavaScript make it hard to
understand but also hard to analyze by only relying on source code.
The most favored approach to this problem is to use typing systems
and ask developers to annotate their code.
There are therefore in addition to basic syntax checking and basic refactoring tools, 
static analyzers that implement many of the features available in more static languages,
such as intelli-sense, which is developed by Microsoft.
But although these tools are very powerful, they are not adapted to some complex cases.
The information accessible at runtime are thus needed to
completely understand the behavior of some piece of code. 
# This information can be harvested though instrumentation.
The main contributions of this paper are:
- An efficient and flexible instrumentation technique of JavaScript.
- An algorithm that allows to compare traces and extract patterns.
- A dynamic visualization that uses traces to see the codebase from a global point to fine grained-interactions.
- An evaluation of the contributions on WordPress

* Dynamic analysis of javascript
Dynamic software analysis is a way of analysing a software
by executing its program while doing measurements.
Accessing information only available at runtime,
allow to complete a static analysis and deepen the understanding of a given piece of software.
# TODO la figure shema:instru:general va servir de support Ã  cette section

#+NAME: dynamic instrumentation shema
#+LABEL: shema:instru:general
#+CAPTION: The instrumentation can be done at multiple layers
#+BEGIN_figure
\centering
\begin{tikzpicture}[x=0.75pt,y=0.75pt,yscale=-1,xscale=1]
%uncomment if require: \path (0,432.3333435058594); %set diagram left start at 0, and has height of 432.3333435058594

%Shape: Rectangle [id:dp3026421788878426] 
\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] (268,232) -- (446.5,232) -- (446.5,308.57) -- (268,308.57) -- cycle ;
%U Turn Arrow [id:dp979064853893437] 
\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] (297,298) -- (297,328.19) .. controls (297,341.52) and (307.81,352.33) .. (321.15,352.33) -- (389.35,352.33) .. controls (402.69,352.33) and (413.5,341.52) .. (413.5,328.19) -- (413.5,308.64) -- (413.5,308.64) -- (396.14,298) -- (378.79,308.64) -- (378.79,308.64) -- (378.79,317.62) .. controls (378.79,317.62) and (378.79,317.62) .. (378.79,317.62) -- (331.71,317.62) .. controls (331.71,317.62) and (331.71,317.62) .. (331.71,317.62) -- (331.71,298) -- cycle ;
%Curve Lines [id:da4591303345723843] 
\draw    (201,328) .. controls (208.84,293) and (230.13,293.95) .. (262.03,290.5) ;
\draw [shift={(264,290.29)}, rotate = 533.5799999999999] [fill={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- (8.93,4.29) -- cycle    ;

%Curve Lines [id:da4688013647243001] 
\draw    (199,223) .. controls (198.02,249.74) and (234.5,253.84) .. (263.25,255.34) ;
\draw [shift={(265,255.43)}, rotate = 182.82] [fill={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]  [draw opacity=0] (8.93,-4.29) -- (0,0) -- (8.93,4.29) -- cycle    ;

%Shape: Rectangle [id:dp8700231437377708] 
\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] (474.5,196.33) -- (535.5,196.33) -- (535.5,270.81) -- (474.5,270.81) -- cycle ;
%Straight Lines [id:da1453252380530321] 
\draw    (485.5,207.33) -- (523.5,207.33) ;


%Straight Lines [id:da7639501705881624] 
\draw    (485.5,218.33) -- (523.5,218.33) ;


%Straight Lines [id:da4351145758238528] 
\draw    (485.5,228.33) -- (523.36,228.33) ;


%Straight Lines [id:da433822944052922] 
\draw    (485.5,239.33) -- (523.36,239.33) ;


%Straight Lines [id:da16085893260822814] 
\draw    (485.5,249.33) -- (523.36,249.33) ;


%Straight Lines [id:da4483544884190436] 
\draw    (485.5,260.33) -- (523.23,260.33) ;


%Shape: Rectangle [id:dp921446397856734] 
\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] (279,257) -- (435.5,257) -- (435.5,298.29) -- (279,298.29) -- cycle ;
%Curve Lines [id:da2916759373241835] 
\draw  [dash pattern={on 4.5pt off 4.5pt}]  (449,287) .. controls (490.37,297.84) and (501.66,308.67) .. (503.9,268.85) ;
\draw [shift={(504,267)}, rotate = 452.73] [fill={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]  [draw opacity=0] (10.72,-5.15) -- (0,0) -- (10.72,5.15) -- (7.12,0) -- cycle    ;

%Down Arrow [id:dp8343034078152856] 
\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] (285,247.71) -- (285,247.71) -- (285,203.87) -- (345,203.87) -- (345,247.71) -- (345,247.71) -- (315,256.2) -- cycle ;
%Shape: Rectangle [id:dp7427753069031857] 
\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] (272,169.71) -- (361,169.71) -- (361,215.71) -- (272,215.71) -- cycle ;
%Callout Right Arrow [id:dp9665594844903169] 
\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] (380,116.71) -- (380,142) -- (341,142) -- (341,153.81) -- (341,153.81) -- (317.5,169.71) -- (294,153.81) -- (294,153.81) -- (294,142) -- (255,142) -- (255,116.71) -- cycle ;
%Flowchart: Multidocument [id:dp4399489164870112] 
\draw  [color={rgb, 255:red, 59; green, 59; blue, 59 }  ,draw opacity=1 ][fill={rgb, 255:red, 225; green, 225; blue, 225 }  ,fill opacity=1 ] (395.4,93.71) -- (481,93.71) -- (481,138.59) .. controls (427.5,138.59) and (438.2,154.78) .. (395.4,144.31) -- cycle ; \draw  [color={rgb, 255:red, 59; green, 59; blue, 59 }  ,draw opacity=1 ][fill={rgb, 255:red, 225; green, 225; blue, 225 }  ,fill opacity=1 ] (384.7,100.51) -- (470.3,100.51) -- (470.3,145.39) .. controls (416.8,145.39) and (427.5,161.58) .. (384.7,151.11) -- cycle ; \draw  [color={rgb, 255:red, 59; green, 59; blue, 59 }  ,draw opacity=1 ][fill={rgb, 255:red, 225; green, 225; blue, 225 }  ,fill opacity=1 ] (374,107.31) -- (459.6,107.31) -- (459.6,152.19) .. controls (406.1,152.19) and (416.8,168.38) .. (374,157.91) -- cycle ;
%Flowchart: Document [id:dp250319717964991] 
\draw  [fill={rgb, 255:red, 255; green, 255; blue, 255 }  ,fill opacity=1 ] (170,94.71) -- (272,94.71) -- (272,156.59) .. controls (208.25,156.59) and (221,178.9) .. (170,164.46) -- cycle ;
%Straight Lines [id:da4826111042138357] 
\draw  [dash pattern={on 4.5pt off 4.5pt}]  (354,257) -- (354,298) ;



% Text Node
\draw (221,129.21) node [scale=1.2] [align=left] {Source\\Code};
% Text Node
\draw (416,131.39) node [scale=1.2,color={rgb, 255:red, 101; green, 101; blue, 101 }  ,opacity=1 ] [align=left] {Libs};
% Text Node
\draw (399,244.71) node [scale=1.2] [align=left] {Runtime};
% Text Node
\draw (354,334) node  [align=left] {Interpreter};
% Text Node
\draw (318,151) node  [align=left] {(1)};
% Text Node
\draw (315,243) node  [align=left] {(2)};
% Text Node
\draw (317.5,193.87) node [scale=1] [align=left] {Compiled\\Code};
% Text Node
\draw (184,213.33) node  [align=left] {System\\Test};
      % Text Node
\draw (179,335.33) node  [align=left] {Unit\\Test};
% Text Node
\draw (498,185.33) node [scale=1.2] [align=left] {Trace};
% Text Node
\draw (397.75,276.81) node [scale=1] [align=left] {bytecode};
% Text Node
\draw (312.5,277.87) node [scale=1] [align=left] {Loaded\\Code};
% Text Node
\draw (314.17,227.33) node [scale=1] [align=left] {Loader};
% Text Node
\draw (321.17,126.33) node [scale=1] [align=left] {Compiler};
% Text Node
\draw (314,313) node  [align=left] {(3)};
% Text Node
\draw (234,241.29) node  [align=left] {use};
% Text Node
\draw (235,302.29) node  [align=left] {use};
% Text Node
\draw (491,306.29) node  [align=left] {measure};


\end{tikzpicture}
#+END_figure

** Workload
# TODO like wang17 We elected to work at the method
#   level because prior work has argued that method call sequences
#   represent the best cost-benefit tradeoff for reproducing field
#   failures

# TODO like wang17 For our experiments, we
#    found that using k = 2 worked well in practice, whereas larger
#    k caused InvariMint to run out of memory for some long traces.
#    Models using larger k values would capture more execution data
While the workload is the preliminary requirement for dynamic program analysis,
acquiring such a workload remain a challenge.
Today, research works that perform dynamic analysis rely on the following techniques to build workload:
- In cite:wang17_behav_execut_compar Wang et al. compare in-field executions to unit test executions using inputs from Massive Open Online Courses (MOOCs)
but also real world systems that use library software in a realistic way.
- In cite:jiang2006multiresolution Jiang et al. detect abnormal traces produced by requests done to server-side software.

The additional knowledge that can be acquired through dynamic analysis 
depends above all on the representativeness and diversity of the inputs.
These inputs can come directly from a user of the application and even through other software, 
but also from robots during automated tests phases.
In the domain of software testing, system tests are often semi-automated and very big,
while unit tests are fully automated and simple.
In most cases, the set of possible entries is infinite, as are the set of executions and therefore the set of tests.
This inherent lack of exhaustiveness and the cost of running tests require us to limit the possible entries.
# Moreover, multiple sets of inputs can represent the behavior,
# so it limits the number of necessary tests.
** Instrumenting to log run-time information
To make dynamic analysis we need to gather dynamic information on our study subject.
It is done by putting probes in the application,
those probes will log information in the form of a trace that will later be analyzed.
When these probes are only used to do measurements, 
to avoid deviating from reality,
they should not produce any side effect, even temporally.
Thus it is necessary to choose what needs to be measured by the probes.
The process of inserting these probes is called instrumentation,
it can be done at multiple layers and at different times.
Choosing when and where to instrument is mainly a matter of
what we want to measure, but also what we have access to.
To ease later analysis relative to a particular layer,
the instrumentation should take place at the closest layer possible.
If the aim is to provide information on source code,
the easiest way is to instrument source code.
In the case of when, 
the instrumentation can be done at compile-time (1),
during the loading (2) of the runtime or by the interpreter (3).
# {{{color(red, I need some references?)}}},
# interception in a pipeline -> intrumentation of content -> getting data from things added during instrumentation
** Analysis

The main ambition here is to make use of what has been done
in software analysis on mature systems cite:wang17_behav_execut_compar
and adapt them to the development pipeline of web applications.
For a tool focussing on software quality improvement
to be widely accepted by the developer community, 
it should not produce false negative
and warning should be ordered by priority.
Moreover in our case due to its dynamic nature,
one of the greatest difficulty when reading javascript code
is to understand the context in which it will be executed.
So on top of a warning, an optimization or a new test,
if it requires the intervention of developers,
some kind of contextualization should be provided.

There is many ways to analyze runtime behaviors as shown in cite:wang17_behav_execut_compar,
behavioral models based on the k-Tails algorithm can be used
to compare mined models from the field to mined models from tests.
But unfortunately, this algorithm needs refined traces,
as computing the behavioral model of raw traces is a waste of resources if half the model end up thrown away.
Considering the pace of changes in web development and the large and heterogeneous community
there are many benefits to adapting behavioral models methods to the way those software are developed.
# TODO use Bridging the gap btw sys and unit tests cite:alex2019bridging
* Contribution
We will now present our contributions, 
starting with our approach to instrument a JavaScript project such as Gutenberg,
then how we analyze traces to help improve the quality of unit tests and the overall understanding of the system.
We choose to instrument JavaScript programs by modifying the text of the scripts,
as it only needs to have access to the code somewhere in the general pipeline, thus being more flexible.
# TODO other choices?
# focus on what dev are modifying.
** Instrumenting
Whether inside a browser for system tests or in a headless interpreter during unit tests,
the collection of execution data is carried out
by adding a new processing step in the compiler, loader or interpreter,
this new step is in charge of modifying the program before its execution,
the modifications are mainly focused on intercepting and storing execution data for later use. 
To instrument web applications, 
we created an Abstract Syntax Tree transformation that can be easily integrated into most pipelines,
it conforms to /TreeJS/, the official Abstract Syntaxe Definition of JavaScript 
and is implemented through the /babeljs/ compiler.
Technically this transformation is done using a simple visitor pattern,
the object and nature of the modifications will be discussed next.
*** Tracing
# log the calls at method level because prior work has argued that method call sequences
# represent the best cost-benefit tradeoff for reproducing field failures cite:Jin_2012.
# TODO wang uses ? to argue this choice
all data available at runtime is not practically possible,
it is therefore essential to choose what should be measured.
To compare executions in production to executions in tests for Java projects,
Wang and al. cite:wang17_behav_execut_compar trace the methods calls,
assuming that in Java, methods are the main reusable structures.
In JavaScript, the main structure holding reusable pieces of code are functions.
However there can be declared in many different ways, namely
=lambda expression= ; =named function= ; =anonymous function= ; 
=object method= ; =Function/eval= ; =class methods=.
The official Abstract Syntax Definition 
regroup them as a union under the name =Function=.
As a common denominator they can all be called using the standard call syntax.
But they can be used and exposed in different ways,
as an attribute of an object ; returned by a function ;
passed as a parameter; in a variable.
This variability allows great flexibility for developers but makes the analysis more complicated.
To make it the least intrusive possible,
we decided to instrument all those kinds of functions
by only adding an instruction at the start of the declaration body.
Only the case of lambda expression without a block (only allowing an expression but no instructions),
needed more modifications,
so we choose to transform the body into a block 
and wrap the original expression in a return instruction, as doesn't change the call stack.
This transformation is common as older versions of javascript don't have lambda expressions.
Back to the instruction content, it adds contextual information to the current trace.
The most important information is the identifier of the called function,
but we also tried to get the values of parameters to see if it was possible to extract some useful knowledge.
Gathering parameters is complicated as it requires to serialize big, complex and recursive structures,
so we choose to limit the serialization to very small depth.
# (2) use the coma operator, not very known
# (3) wrap it with a call, problem with scope
*** Dynamic instrumentation
can be done in a browser, we found 2 ways to instrument JavaScript that allow changing the text of the scripts.
One can be implemented using a browser extension to modify the way a page is loaded,
the other method uses the /DevTools/ API to intercept HTTP requests and responses.
The first method is more accessible as it only needs to install a browser extension and have access to the DOM,
the second one is more intrusive and needs to be launch as a new OS process,
but it gives access to low-level API and by default make use of the cache, load scripts asynchronously
and offload the instrumentation to a background process.
The loading protocol of scripts in a web page[fn::https://html.spec.whatwg.org/multipage/scripting.html#script] 
is very complex, to make it clearer
the declaration of scripts can be split into 3 kinds, as shown in Listing [[shema:instru]].
Those 3 kinds of script tags are used in different situations.
The first one is an inline script so the content is part of the page,
the second one loads a script file from the same domain as the page,
and the third one loads a script file from a remote domain.
For performances reasons non-inline scripts are asynchronously loaded, 
and the file they are referring to can not be modified.
Moreover, there is no http request to load inline scripts,
it is thus only modifiable at a network level by modifying the original page.
To avoid misses, each instrumentation needs to be done before (*) the javascript interpreter 
parse and evaluate the content of the given scripts.

# frame=single,framesep=20pt,
#+NAME: dynamic instrumentation shema
#+ATTR_LaTeX: :float t :options fontsize=\tiny
#+LABEL: shema:instru
#+CAPTION: The different approaches to interecpt different kind of script in the web browser
#+BEGIN_SRC bash :eval never
--------<script>xxxxxxxxxx</script>-----<script src="xxxxx.js"></script>----<script src="xxxx.com/xxxx.js"></script>----
               \          /              \                            /      \                                    /   
 DOM           (a)      (*)              (b)                        (*)      (c)                                (*)  
                 \------/                  \                        /          \                                /   
                                            \                      /            \                              /
---------------------------------------------\--------------------/--------------\----------------------------/---------
                                              \                  /                \                          /
 BROWSER NETWORK LAYER                         \               (d)                 \                       (d)
                                                \              /                    \                      /
-------------------------------------------------\------------/----------------------\--------------------/-------------
                                                  \          /                        \                  /
 INTERNET                                                                              \-(c1)------(c2)-/
                                                                                             \    /
#+END_SRC

**** The DOM layer
# it can cause major slow down on a page loading if it is not well made[fn::https://www.debugbear.com/blog/measuring-the-performance-impact-of-chrome-extensions#the-performance-impact-of-ad-blockers-and-privacy-tools]
is were the global scope lies.
Thanks to the Mutation Observer API[fn::https://developer.mozilla.org/en-US/docs/Web/API/MutationObserver],
it is possible to listen to parsing events
and modify scripts loaded on the page, as the DOM is constructed.
The script in charge of the instrumentation
needs to be directly included in the original page as the first script,
or dynamically added during loading.
Dynamically adding script tags can be done with a web browser extension[fn::https://developer.chrome.com/extensions]
or using an API[fn::https://chromedevtools.github.io/devtools-protocol/] accessible from outside of the web browser.
When a parsing event is triggered, we handle the 3 kinds of scripts in different ways. 
Inline scripts are the easiest to modify, in (a) we replace the content of the script with its instrumented version.
For local scripts, in (b) the script file is programmatically fetched, then its content is instrumented and assigned as its new content, the script becomes inline.
Remote scripts are more complex, in (c) we need to change the URL to redirect it to a local HTTP server.
This local server will fetch the original script content (c1) then instrument it (c2) and finally send back the modified version.

This approach is functionally correct
but it does not scale very well and end up with some noticeable impact on performances.
On one hand it can't make use of the web browser cache,
so it requires to instrument web pages at each load.
On the other hand, the instrumentation logic is executed in the same environment
as the web application, leading to perturbations during loading.
**** Instrumenting http responses
is the second method that we tried.
It is more efficient as it makes use of the web browser cache
but it can only be implemented through the Fetch domain[fn::https://chromedevtools.github.io/devtools-protocol/tot/Fetch] of the Devtools API.
It is much more simple as we only need to intercept and instrument incoming responses to requested scripts.
The instrumentation is done in another process,
relieving the web browser of some stress and isolating the instrumentation logic from the rest of the application. 
For now, it does not work on inline scripts but instrumenting HTML along with their inline scripts could be used.
It uses Puppeteer[fn::https://github.com/GoogleChrome/puppeteer] as a wrapper around the DevTools API 
to grant some more portability between OSes.
*** Compile-time instrumentation
is needed to instrument unit tests in most javascript projects.
In fact, unit tests are often run out of web browsers, in more lightweight interpreter like /nodejs/.
Moreover all of the big javascript projects use some kind of compilation pipeline,
as it allows for greater development flexibility and automating retro-compatibility.
The more used js compiler are /Browserify/ and /Babeljs/ used together.
** Analyzing
Considering the size and complexity of today web applications,
any analysis tool aiming for real-world software should consider scalability as its major constraint.
But improving a software can be split in 3 steps,
detecting a problem, then finding its position and finally solving the problem.
Detecting and finding problems don't need to be very precise nor exhaustive so it can accommodate with a big quantity of data.
And solving a problem should only require a partial view of the available data.
Moreover here traces produced through instrumentation are structured.
So we choose to use and extend a relational database to analyze and process traces,
then an interactive visualization to display feedback at different stages.

*** The processing of traces
# One of the big challenges is to process the logs fast.
can be done in multiple ways.
We tried to apply the methodology of Wang et al. cite:wang17_behav_execut_compar 
on the analysis of runtime traces of calls to methods in Java,
but due to the variety of symbols and the size of our traces,
this method cannot meet our requirements for memory and efficiency.
In our case realistic traces contain at least 1000 unique symbols and contain around 1 million entries.
In fact, we are 2 orders of magnitude higher in terms of the number of symbols and the size of the traces
compared to the maximum values evaluated in cite:beschastnikh2013unifying.
Moreover, for a project like WordPress, no developer needs a representation this precise of the whole system.
That is why we moved towards a more NLP-oriented approach, using n-grams.
Using n-grams to analyze source code is already relevant as shown by Hindle, Abram, et al. cite:hindle2012naturalness.
And n-grams of traces can be used to detect abnormal execution cite:jiang2006multiresolution.
It allows processing traces halfway between purely statistical analysis and behavioral analysis.
With this new information, on top of giving developers a representation of the context of the execution of their code,
it might allow us to run algorithms like k-Tails more efficiently.
But if done naively, enumerating and processing n-grams can also be wasteful,
consequently, we choose a more recursive and incremental approach
that enumerate n-grams starting from a set of given symbols.
Thus it relies on the same assumption than k-Tails but only needs and gives a partial view.
Anyway in the case of tests improvements,
there is a cost at adding tests as they require maintenance and computing power,
so by relying on statistics of already computed n-grams,
we can on behaviors more relevant to test (see the evaluation section for examples).
*** Interactive visualization
can be used to get a global view on a large quantity of data.
To ease the reading of that information,
it is essential to aggregate relevant data while allowing to zoom on particular parts.
In a large codebase such as Gutenberg,
representing all functions declared in the codebase can be difficult,
mostly because of the large number of functions
--almost 10000 in the case of Gutenberg--
but also because we want to show relations between functions.
We produced two representation,
that comes in complement to the code.
The first representation uses a tree structure
similar to those found in some popular IDE
where the outline of source files are shown in the file explorer.
Here in addition to the basic folding tree, the size and color of nodes are proportional to some metrics
that we can compute from our traces.

#+NAME: example rectpacking
#+LABEL: shema:example:rectpacking
#+CAPTION: Example of our global view representation
#+ATTR_ORG: :width 600
#+ATTR_LATEX: :height 2.5in
[[file:images/nested_rec_example.pdf]]

Figure [[shema:example:rectpacking]] is an example of this representation.
With the size of nodes that are proportional to the usage of function in production
and the colors are proportional to the usage of function in unit tests.
It allows to easily see functions used many times but never tested.
With this representation, it is even possible to represent the parameters passed to functions or other structures similar to trees.
However there are some limitations,
as it is necessary to keep the proportion right to be able to compare elements.
Circles are not usable to represent nodes because of geometric limitations, 
but we successfully used rectangles in this particular layout that also allows seeing the name of nodes.
In this layout, the size of a node is its height.
The metrics usable to compute the size of nodes are also limited as they need to be aggregated with a sum.
Where used in a system that allows interactivity, it is possible to zoom on nodes
and using an IDE it is possible to jump to the code and to the next representation that we will be presented in the next paragraph. 

The second representation shows the context of functions during execution.
It can be used on a function to understand its context of use
and allows grasping how a function is used
by presenting which context should be reproduced to test that function efficiently.
It dynamically mines the traces using the processing method presented earlier.
Here the produced n-grams are fused to construct a graph with the starting function at its center.
Each node represents calls to a function, the width represents the number of calls made to this function,
each transition width represents the number of times a sequence of calls was made.
Nodes are given the same color when they represent calls to the same function.
Here it is possible to dynamically search for bigger n-grams and using an IDE, it is also possible to jump to code.
Moreover to compensate for the merge of nodes, 
while hovering a link, it highlights other links contained in the same n-grams.
This representation is made to also accommodate a model mined with a k-tail algorithm.
As an example, the Figure [[fig:flow:loop]] shows the context of a function called in a loop 
that always start after a unique function
and end with another unique function.

#+NAME: loop
#+CAPTION: Context of a function called in a loop
#+LABEL: fig:flow:loop
#+ATTR_ORG: :width 600
#+ATTR_LATEX: :width 0.5\textwidth
[[file:images/flowgraph4.png]]

# ** producing useful feedback
# Zeller and al. cite:alex2019bridging show how to synthesize new unit tests based on system tests.

# impact

# the majority use vs code
# **** Representing mined information
  # Another challenge is to relate the information mined from logs in a meaning and useful way.
* Evaluation
We will now show the results obtained through the analysis of Gutenberg,
trough a simple procedure and using limited inputs
to show that even with a simple experimental procedure,
it is possible to analyze a large codebase and propose improving modifications.
** Experimental procedure
all the experiments were run on an /ArchLinux/, /intel/ /i7/ laptop with 8go ram.
the source code of WordPress was first instrumented during compilation using our AST transformation.
production traces were made on an instrumented chrome browser,
the user inputs are reproducing the writing of a very short post only made of text.
Tests traces were made by running the unit tests with /NodeJs/, each run produces many traces, one for each test.
the following results will present 12 production traces and 3 sets of unit test traces each containing 767 traces.
for a total of 6.3 million calls
** Macro Analysis
We can get a fist look at our data in Figure [[shema:venn]] using a Venn diagram.
At first glance, we can see that our system tests only used a small part of declared functions,
nonetheless around one-third of used functions were not tested.
with this figure, it can be concluded that at least 1122 functions need new tests.
But we can't conclude anything on functions tested but not used as our set of input is restricted.

# \begin{figure}[htp]
# \centering
# \subfloat[Caption1\label{s:venn}]{%
#   \includegraphics[width=0.5\textwidth]{images/venn_functions.pdf}%
# }\hfil
# \subfloat[Caption1\label{fig:subim2}]{%
#   \includegraphics[width=0.5\textwidth]{images/venn_functions.pdf}%
# }

# \caption{Caption for this figure with two images}
# \label{fig:image2}

# \end{figure}

#+NAME: venn
#+LABEL: shema:venn
#+CAPTION: Venn Diagram on functions in Gutenberg
#+ATTR_ORG: :width 600
#+ATTR_LATEX: :height 5cm
[[file:images/venn_functions.pdf]]

#+NAME: wordpress ditrib
#+CAPTION: Test coverage of functions used in production
#+LABEL: fig:rectpacking
#+ATTR_ORG: :width 600
#+ATTR_LATEX: :width 0.75\textwidth
[[file:images/nested_rec_exp_with_color_bar.pdf]]

To see which functions need new tests,
the Figure [[fig:rectpacking]] present a static view of 
the first interactive viewer presented in the contribution.
The precision of this representation allows to 
find the most used functions that are never tested.
As explained in the contribution,
the structure of the code base is preserved down to the functions,
data available on functions are aggregated to form the nodes of the tree,
it is thus possible to traverse the tree and find functions that need new tests by order of priority. 
On the one hand, the more a function is called, the larger its rectangle is. 
On the other hand, the more a function is used without being tested, the more the color tends towards red, 
and the more the function is tested, the more its color tends towards dark green.


# file:images/circlepack_cleaned_printed.pdf

The Figure [[fig:rectpacking]] shows that 62% of used functions are tested at least one time
and the functions never unit tested makes it for 6.8% of calls.
The interactive version was used to find a few functions needing new tests.
*** venn :noexport:
We use a Venn Diagram to compare the set of functions used in production to the set of function used in tests,
to globally assess of the quality of tests.
# ***** Venn diagram with symbols of functions
  #+BEGIN_SRC ditaa :file images/venn_prod_test_calls_symbols.png

    +------------------------------------------------------+
    | instrumented                                         |
    | symbols              +-------------------------+     |
    |                      |                         |     |
    |         +------------+----------+              |     |
    |         |            |          |              |     |
    |         |            |  prod    |    prod      |     |
    |         |            |   n      |              |     |
    |         |    test    |  test    |              |     |
    |         |            |          |              |     |
    |         |            +----------+--------------+     |
    |         |                       |                    |
    |         +-----------------------+                    |
    |                                                      |
    +------------------------------------------------------+

  #+END_SRC
# ***** Venn diagram with function's symbols and parameters
  #+BEGIN_SRC ditaa :file images/venn_prod_test_call_symbols_and_parameters.png

                           +-------------------------+     
                           |                         |     
              +------------+----------+              |     
              |            |          |              |     
              |            |  prod    |    prod      |     
              |            |   n      |              |     
              |    test    |  test    |              |     
              |            |          |              |     
              |            +----------+--------------+     
              |                       |                    
              +-----------------------+                    

  #+END_SRC
***** distribution of calls on dataset per gutenberg package       :noexport:
  #+BEGIN_EXAMPLE
  production/test calls sorted by number of occurences of production.
  y axis show # of calls
  x axis show calls, only some interesting calls should be visible.
  #+END_EXAMPLE

  #+NAME: wordpress ditrib
  #+CAPTION: Coverage of functions called in production (grey) by functions called in test (red), red dot are showing cases when functions are used in production but never used in test 
  #+ATTR_ORG: :width 600
  #+ATTR_LATEX: :width 5in
  [[file:plots/distrib.png]]
  #+BEGIN_EXAMPLE
  production/test calls sorted by number of occurences of production.
  y axis show # of calls, (log2 scale)
  x axis show calls, only some interesting calls should be visible.
  data faceted by package
  #+END_EXAMPLE

  #+NAME: wordpress multi-ditrib
  #+CAPTION: Coverage of functions called in production (grey) by functions called in test (red) split by plugin, red dot are showing cases when functions are used in production but never used in test  
  #+ATTR_ORG: :width 600
  [[file:plots/multidistrib3.png]]
***** aaa  :noexport:
  #+NAME: wordpress multi-ditrib
  #+CAPTION: Distribution of number of calls per JS functions for production (grey) for tests (red) in traces of Wordpress split by packages with values truncated to 1000 calls, to make it bigger.
  #+ATTR_ORG: :width 600
  [[file:plots/multidistrib.png]]
** Preparing new tests
# Figure loop;deprecated;explosion;long chain;

In the previous section, functions lacking tests were found,
here the aim is to understand the context of these functions to produce the most relevant unit tests.
The second representation presented in the contribution is designed to achieve that goal.

\begin{figure}[htp]
\centering
\subfloat[Sequence of non-tested functions\label{fig:flow:linear}]{%
  \includegraphics[width=0.45\textwidth]{images/instant3.pdf}%
}\hfil
\subfloat[Called in a loop\label{fig:flow:loop2}]{%
  \includegraphics[width=0.45\textwidth]{images/instant4_clean.pdf}%
}
\caption{Context of some functions}
\label{fig:image2}
\end{figure}

On the left, the figure \ref{fig:flow:linear} shows a long sequence of calls,
containing multiple functions never tested
by reproducing this context it would be possible to add a first test to 6 functions in one go
thus reducing the overhead.
looking in more detail on those non-tested functions, they are simple accessors
and the pale functions are well tested, but looking at the code,
they are part of a fairly complex program made of many closures (functions returning functions).
so more tests won't do any harm here.
the figure \ref{fig:flow:loop2} shows a loop,
it is similar to the example presented in the contribution but in a more complicated case.
There are more branches at the start and the end of the context
so the new tests skeleton should be made of these sequence of calls.
Once the sequence is chosen, it is even possible to fetch the parameters in the traces,
and fill up the calls parameters.


# #+NAME: wordpress createNamespace context
# #+ATTR_ORG: :width 600
# #+LABEL: fig:flow:loop
# #+CAPTION: context usage of a function from field compared to tests, the width of rectangles and transitions is proportional to the number of call in production and functions lacking test are darker
# [[file:images/flowgraph4.png]]

***** Precise analysis of methods/functions usage context from field compared to tests :noexport:

#+NAME: wordpress createNamespace context
  #+CAPTION: callback function wrapping a retruned selector in createNamespace, usage context from field compared to tests, la couleur des noeuds reprentente le rapport entre le nombre d'utilisations en production par rapport aux tests
  #+ATTR_ORG: :width 600
  [[file:images/flowgraph1.png]]

* Conclusion
We have created an analysis tool for dynamic languages,
capable of tracing information accessible at runtime,
then process it 
and finally display useful feedback.
The results obtained can help developers at understanding the behavior of a piece of software,
but it can also be feed to more classical automated test generation tools.
This tool has been evaluated on WordPress 
and could easily be adapted to other web applications or JavaScript packages. 
For now, it is integrated into Visual Studio Code to interact with source code.
The repository containing the resources presented in this report can be found at [[https://github.com/quentinLeDilavrec/m1_internship]]. 
There are many improvements possible on this tool, some of them were mentioned earlier
but the aim is to push developers on taking this tool further by adapting it to their needs.
# * References                                                         :ignore:
bibliographystyle:plain
bibliography:references.bib
** links                                                  :noexport:
# splncs splncs03 plain
- [[https://doi.org/10.1016/j.infsof.2019.05.008][On the Use of Usage Patterns from Telemetry Data for Test Case Prioritization]] Tests improvements
- [[https://people.cs.umass.edu/~brun/pubs/pubs/Wang17icst.pdf][Behavioral Execution Comparison: Are Tests Representative of Field Behavior?]] paper using synoptic
- [[https://github.com/INRIA/intertrace]]
- https://people.inf.ethz.ch/suz/publications/natural.pdf https://github.com/labri-progress/naturalness-js application of natural language processing to computer software
- [[https://arxiv.org/pdf/1906.01463.pdf][Bridging the Gap between Unit Test Generation and System Test Generation]] feedback loop
- [[http://ceur-ws.org/Vol-971/paper21.pdf]]
- http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=877A01775995830BB127116FB11BAB49?doi=10.1.1.323.3411&rep=rep1&type=pdf
- [[https://cs.uwaterloo.ca/~m2nagapp/courses/CS846/1171/papers/hindle_icse12.pdf][Lossless compaction of model execution traces]]
- [[https://livablesoftware.com/conflictjs-javascript-libraries-conflicts/]]

# # eval:    (setq org-latex-pdf-process '("pdflatex -bibtex -shell-escape -interaction nonstopmode -output-directory %o %f" "pdflatex -bibtex -shell-escape -interaction nonstopmode -output-directory %o %f" "pdflatex -bibtex -shell-escape -interaction nonstopmode -output-directory %o %f"))
* Journal                                                         :noexport:
** [2019-05-15 Wed]
*** DONE use Iroh with Mutation Observer to wrap scripts
** [2019-05-16 Thu]
*** DONE adapt [[file:IrohMutationObserverLogger]] to use devTools
** [2019-05-21 Tue]
*** DONE Logging
  Some ways to intrument javascript programs
**** https://stackoverflow.com/questions/11853256/how-to-get-javascript-function-calls-trace-at-runtime
**** https://stackoverflow.com/questions/7439570/how-do-you-log-all-events-fired-by-an-element-in-jquery
**** https://stackoverflow.com/questions/5033836/adding-console-log-to-every-function-automatically

**** Wrapping

***** https://www.npmjs.com/package/call-log
***** https://stackoverflow.com/a/5034657/9854053
  #+BEGIN_SRC js
  function augment(withFn) {
      var name, fn;
      for (name in window) {
          fn = window[name];
          if (typeof fn === 'function') {
              window[name] = (function(name, fn) {
                  var args = arguments;
                  return function() {
                      withFn.apply(this, args);
                      return fn.apply(this, arguments);

                  }
              })(name, fn);
          }
      }
  }

  augment(function(name, fn) {
      console.log("calling " + name);
  });
  #+END_SRC
***** https://stackoverflow.com/a/11854146/9854053
  #+BEGIN_SRC js
  //**************************Set up your functionLogger*****************//
  var functionLogger = {};

  functionLogger.log = true;//Set this to false to disable logging

  /**
   * Gets a function that when called will log information about itself if logging is turned on.
   *
   * @param func The function to add logging to.
   * @param name The name of the function.
   *
   * @return A function that will perform logging and then call the function.
   */
  functionLogger.getLoggableFunction = function(func, name) {
      return function() {
          if (functionLogger.log) {
              var logText = name + '(';

              for (var i = 0; i < arguments.length; i++) {
                  if (i > 0) {
                      logText += ', ';
                  }
                  logText += arguments[i];
              }
              logText += ');';

              console.log(logText);
          }

          func.apply(this, arguments);
      }
  };

  /**
   * After this is called, all direct children of the provided namespace object that are
   * functions will log their name as well as the values of the parameters passed in.
   *
   * @param namespaceObject The object whose child functions you'd like to add logging to.
   */
  functionLogger.addLoggingToNamespace = function(namespaceObject){
      for(var name in namespaceObject){
          var potentialFunction = namespaceObject[name];

          if(Object.prototype.toString.call(potentialFunction) === '[object Function]'){
              namespaceObject[name] = functionLogger.getLoggableFunction(potentialFunction, name);
          }
      }
  };


  //**************************Set up your namespace functions*****************//
  var namespaceObject = {};

  namespaceObject.test1 = function(a, b, c, d, e) {
      namespaceObject.test2(a + b, c + d + e);
  };

  namespaceObject.test2 = function(ab, cde) {

  };





  //**************************Add logging to your namespace functions*****************//
  functionLogger.addLoggingToNamespace(namespaceObject);






  //**************************Test it out*****************//
  namespaceObject.test1("alli", "gator", 3, 4, 5);
  #+END_SRC
***** https://stackoverflow.com/questions/5226550/can-i-override-the-javascript-function-object-to-log-all-function-calls/12425499#12425499
***** Proxy https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Proxy
      - https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Proxy/handler/apply
****** On function
  #+BEGIN_SRC js
  function sum(a, b) {
    return a + b;
  }
  const accu = []
  const handler = {
    apply: function(target, thisArg, argumentsList) {
      console.log(`Calculate sum: ${argumentsList}`);

      // expected output: "Calculate sum: 1,2"

      accu.push({
        name: target.name,
        args: argumentsList
                });

      return target(argumentsList[0], argumentsList[1]) * 10;
    }
  };

  var proxy1 = new Proxy(sum, handler);

  console.log(sum(1, 2));
  // expected output: 3
  console.log(proxy1(1, 2));
  // expected output: 30

  console.log(proxy1.call(this,1, 2));

  console.log(proxy1.apply(null,[1, 2]));

  console.log(accu);
  #+END_SRC

****** On class
  #+BEGIN_SRC js
  function Hero(name, level) {
      this.name = name;
      this.level = level;
  }

  // Adding a method to the constructor
  Hero.prototype.greet = function() {
      return `${this.name} says hello.`;
  }

  // Creating a new constructor from the parent
  function Mage(name, level, spell) {
      // Chain constructor with call
      Hero.call(this, name, level);

      this.spell = spell;
  }

  Mage.prototype = new Hero;

  // Initializing a class
  class HeroC {
      constructor(name, level) {
          this.name = name;
          this.level = level;
      }

      // Adding a method to the constructor
      greet() {
          return `${this.name} says hello.`;
      }
  }

  // Creating a new class from the parent
  class MageC extends HeroC {
      constructor(name, level, spell) {
          // Chain constructor with super
          super(name, level);

          // Add a new property
          this.spell = spell;
      }
  }

  const loggerC = className => {
    return new Proxy(new className(), {
      get: function(target, name, receiver) {
        if (!target.hasOwnProperty(name)) {
          if (typeof target[name] === "function") {
            console.log(
              "Calling Method : ",
              name,
              "|| on : ",
              target.constructor.name
            );
          }
          return new Proxy(target[name], this);
        }
        return Reflect.get(target, name, receiver);
      }
    });
  };

  const logger = obj => {
    return new Proxy(obj, {
      get: function(target, name, receiver) {
        if (!target.hasOwnProperty(name)) {
          if (typeof target[name] === "function") {
            console.log(
              "Calling Method : ",
              name,
              "|| on : ",
              target.constructor.name
            );
          }
          return new Proxy(target[name], this);
        }
        return Reflect.get(target, name, receiver);
      }
    });
  };

  //const instance = logger(Mage)
  const instanceC = loggerC(MageC)

  console.log("a");

  instanceC.greet()
  #+END_SRC

***** setPrototypeOf https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/setPrototypeOf
       - less spread, less clean but change already existing class
       not sure here

***** Modify program text (using an AST https://github.com/benjamn/recast)
***** use api of the webbrowser
      - seem to be unstable on most browsers
      - faster?
      - cleaner
      - not really portable
      - complicated
*** DONE Temporal Invarients Mining
    CLOSED: [2019-05-30 Sun 21:13] basic impl don't scale

  - [X] get methods call from log
  - [X] give it to a model inference algorith like kTails (impl. in InvariMint)

*** DEFERRED Using maps of mignifiers to compress logs
    CLOSED: [2019-06-30 Sun 21:12] and get function position in source
  //https://www.html5rocks.com/en/tutorials/developertools/sourcemaps/
  particuliÃ¨rement pour le cas des remotes sources.

*** DEFERRED Recursive Mutation Observers for iframes?
    CLOSED: [2019-06-30 Sun 21:12]
  detect it, then attach a MO to it.

*** DEFERRED Serialize arguments in a mindfull way
    CLOSED: [2019-06-30 Sun 21:12]
  control deph and type

*** DONE intercept WordPress tests
    CLOSED: [2019-06-04 Tue 16:37]
  modifying imports?
**** HALF use babel for plugins browserification
*** DEFERRED hash of inline scripts
    CLOSED: [2019-06-30 Sun 21:12]
allow to compare duplicated scripts
but don't work without maps or between compilations.

*** CANCELLED 2 passes for prefetch
    CLOSED: [2019-05-21 Tue 15:52]
  switched Fetch API of v8 works like normal requests

*** CANCELLED reduce Iroh modifications
    CLOSED: [2019-05-21 Tue 15:51]
  switched to babeljs
** [2019-05-22 Wed]
*** Advancements made on first week
- I spoke with Nicolas H. and Javier C. about what I had done to prepare the internship :: Explaining the context, so that they can give me pointers to useful resources
- Javier convinced me to use v8 devTools to do the wrapping
  - Sadly traces created by v8 are done by sampling and don't get all calls (confirming some of my observations during preparation), Profiling don't get parameters
  - But the Debugger and Runtime interfaces are able to get and set scripts content :: So I adapted the [[file:IrohMutationObserverLogger]]
    - The content of inline scripts can't be changed using v8 so the new method only apply to local and remote script files
    - It work well without changing script loading and evaluation behavior
    - But the wrapping have a linear complexity, leading to big loading time is some cases like when creating a new WP post on the web interface
  - Ater some more research, I found an experimental interface of devTools called Fetch which intercept HTTP requests :: Leading to the same wrapping but only at the cost of a few ms (it now uses cache and wrapping are paralyzed by default)
- I am now on making the interception in the tests of WordPress
  - Most tests are in plugins (for example the new blocs plugin introduced by gutemberg)
- I am also thinking about better ways of identifying functions, making use of calls parameters and wrapping as much as possible during compilation

** [2019-05-27 Mon]
*** Number of calls with puppeteer getting and  writting on disk 1 per call
fail because resetting  this.log and not log
#+BEGIN_EXAMPLE
cat * | wc
      0       1 139670000
#+END_EXAMPLE
more like that with 10 one per call (to see available bandwith)
#+BEGIN_EXAMPLE
cat * | wc
      0       1 65380000
#+END_EXAMPLE

*** HALF read [[https://doi.org/10.1016/j.infsof.2019.05.008][On the Use of Usage Patterns from Telemetry Data for Test Case Prioritization]]
- Telemetry / interception of requests
- Fingerpints
*** HALF look at [[https://github.com/INRIA/intertrace]]
- tracing API, give methods to trace events
- Django
** [2019-05-28 Tue]
*** Summary
We summaries the advancement made until now (also speaking about possible improvements)
Starting with possible uses of what we are able to produce, then explaining how we produced it.
**** Uses of the data produced
- Calls made during tests    + Functions declared in code   => Static test coverage
- Calls made during tests    + Calls made during production => Dynamic/Behavioral Test coverage
- Functions declared in code + Calls made during production => Code usage
**** Tools developped until now for this internship
The following tools require the analysis of code AST. (respecting the ESTree specification)
Instrumentation is mostly done at compile time using Babeljs,
then during runtime logs are pushed to a global variable similar to a list.
***** Functions declared in code
Dynamic lookup in source using ESlint, it underline problems, and propose/apply fix.
***** Calls made during tests
Each test is run in an isolated environment,
before each test the global variable storing logs is instantiated,
after each test logs are written on disk.
***** Calls made during production
The browser is launched using puppeteer
each launched page instantiate the global variable storing logs.
Here logs are flushed every n intercepted calls to lower the header part.

** [2019-06-01 Sat]
*** DONE read [[https://people.cs.umass.edu/~brun/pubs/pubs/Wang17icst.pdf][Behavioral Execution Comparison: Are Tests Representative of Field Behavior?]] again, to recenter the project and construction of the arguments that will be soon developed
    CLOSED: [2019-06-09 Sun 16:38]
Confronting my experience of the last weeks I hope to see this paper in a new light.
**** vocabulary
- used in production -> *used in the field*
- software testing
- field data
- model inference
- Behavioral models
- behavior
**** context
Software testing is the most widely used approach
for assessing and improving software quality
**** industrial aim
Provide insight for developers and suggest a
better method for measuring test suite quality
**** claims
Tests may not be representative of how the software is used in the field.
To prove it, they apply the presented method on 1 end-user and 3 client software.
Automatically-generated tests created by a tool
targeting high code coverage (static analysis) only marginally improves the testsâ
behavioral representativeness.
They hypothesize that the finer-grained model is better suited for identifying behavioral
differences and is thus more useful in assessing test suite quality than coverage and mutation.
**** achievements
Present a model based on temporal invariant (dynamic analysis)(kTails-based invariants[6][10]).
But also compare to coverage based models (industry usage [1][22][27][28][30])
and a mutation-based model (industry usage[33]).
**** intro
- There is not a broad understanding of the extent to which test cases may fall short in representing real-world executions,
- The ways in which tests and realworld executions differ :: help to create novel metrics
- What can be done to bridge this gap in an effective and efficient way :: measure improvements of test suites

**** Behavioral models
- a set of source code statements covered by executions (test/field)
- a set of methods covered by executions
- a set of mutants killed by executions
- a set of temporal invariants over executed methods that hold over the executions.

*** HALF look at mutation based models for tests
*** STARTED read https://people.inf.ethz.ch/suz/publications/natural.pdf and look at https://github.com/labri-progress/naturalness-js
*** DONE implement SQL requests doing the same things as grep and uniq -c
    CLOSED: [2019-06-04 Tue 14:41]
#+BEGIN_SRC sql
SELECT CONCAT(path,':',sl,'',sc,':',el,':',ec), params, COUNT(*), SIGN(session) FROM CALLS
WHERE path = ? AND sl = ? AND sc = ? AND el = ? AND ec = ?
GROUP BY path, sl, sc, el, ec, params, SIGN(session)
#+END_SRC
*** DEFERRED implement SQL requests doing behavioral inferences
    CLOSED: [2019-06-19 Wed 14:42] maybe extending from my postgres recursive function
#+BEGIN_SRC sql
SELECT * FROM
  calls,
  (SELECT root, session, next_line FROM calls
  WHERE calls.path = currpath
  AND calls.sl = currsl
  AND calls.sc = currsc
  AND calls.el = currel
  AND calls.ec = currec) AS init
WHERE init.root = calls.root
AND init.session = calls.session
AND init.next_line = calls.line
#+END_SRC
*** HALF read https://people.cs.umass.edu/~brun/pubs/pubs/Beschastnikh15tse.pdf
*** DONE look at invarimint hadoop 2017 http://isisell.com/freeupload/741894_5942935424157615043.pdf
    CLOSED: [2019-06-09 Sun 16:39]
*** TODO show https://app.logrocket.com/nvhohr/test/sessions
** [2019-06-03 Mon]
*** HALF look at https://docs.timescale.com/v1.3/introduction
- superset of SQL
- didn't see INFILE insertions
- really adapted to logs but only one order improvements?
** [2019-06-05 Wed]
*** TODO read [[https://arxiv.org/pdf/1906.01463.pdf]]
*** TODO look at [[https://github.com/github/semantic]]
*** CANCELLED prototype idea about splitting logs by gutenberg modules
    CLOSED: [2019-06-19 Wed 14:38] Done with the postgres function searching recursivly from some symbols
Something like =extract logs l where dist(l,c)<d with c a call to a function from current package=.
Then it can be used to color/represent logs,
or otherwise

*** DONE meeting with Benoit B. and Javier C.
**** STARTED plot #n-gram over value of n
Need data, hopefully make first batch next +friday+ monday.
***** DONE count ngrams
      CLOSED: [2019-06-10 Mon 16:51]
****** 1-grams
=sort | uniq -c=
****** simulating n-grams calculation using 1-gram technic and transforming each line into it and x previous lines
- keep x lines in a circular array
- read lines with stream
- output to 1-gram algo as a stream current and x prev lines
****** results
uniq ngrams count grow linearly from ~20k up to 70k for 10-grams
#+BEGIN_SRC

#+END_SRC
** [2019-06-07 Fri]
*** STARTED read [[http://ceur-ws.org/Vol-971/paper21.pdf]]
*** CANCELLED Produce logs
    CLOSED: [2019-06-07 Fri 16:10] Bug, no logs produced, investigating in following days.
- with Benoit and Javier on their computer, respectively Ubuntu and OSX.
- for Docker using GUI, with OSX it needs XQuartz, that is difficult to install
- on first docker usage need to start the deamon, =sudo systemctl start docker=
- on first use of X11 combined with docker run =xhost local:root= allowing local clients to communicate with X11 server
- [X] need to automatically create temporary directory for logs if it doesn't exist
** [2019-06-08 Sat]
*** DONE make experimental setup ready
Now working with public IP.
Last Friday problems were coming from a static config (localhost) of Gutenberg setup scripts.

*** TODO reduce number of nodes intercepted
- using some sort of plugin structure? (at least make it easier)
**** Gutenberg
- filter arrow function smaller than something and inside reduce
- get comment to enable or disable instrumenting
*** WAITING format hints better
- print firsts most used cases that are not tested
- if hint size less than something print firsts most used cases that are not tested enough
- normalize results by something
*** DONE make some logs myself
    CLOSED: [2019-06-10 Mon 13:53]
*** DONE vscode plugin is working well
*** TODO improve functions identification using a dict to check for names collisions at compile time.
functions instrumented later (runtime (in eval?)) can be named by other means
*** DONE show line 57537 to Javier of file logs/2
    CLOSED: [2019-06-10 Mon 09:31]

** [2019-06-12 Wed]
*** DONE switch to postgress for LTREE and custom functions
    CLOSED: [2019-06-16 Sun 14:47]
http://patshaughnessy.net/2017/12/13/saving-a-tree-in-postgres-using-ltree
#+NAME: Creation table
#+BEGIN_SRC sql
CREATE EXTENSION ltree;
CREATE TABLE calls (
  origin char(10) NOT NULL,
  path ltree NOT NULL,
  sl integer NOT NULL,
  sc integer NOT NULL,
  el integer NOT NULL,
  ec integer NOT NULL,
  session integer NOT NULL,
  line integer NOT NULL,
  params json DEFAULT NULL,
  PRIMARY KEY (origin,session,line)
);
create index ON calls using gist(path);
create index ON calls(path,sl,sc,el,ec);
#+END_SRC

#+NAME: Testing calls table
#+BEGIN_SRC sql
CREATE OR REPLACE FUNCTION public.formatPath(s char)
 RETURNS ltree AS $BODY$
BEGIN
    return text2ltree(REPLACE(REPLACE(REPLACE(REPLACE(s,'Ã§','Ã§Ã§'),'-','Ã§1'),'.','Ã§0'),'/','.'));
END;
$BODY$ LANGUAGE plpgsql IMMUTABLE;
CREATE OR REPLACE FUNCTION public.formatPath(l ltree)
 RETURNS char AS $BODY$
BEGIN
    return REPLACE(REPLACE(REPLACE(REPLACE(ltree2text(l),'.','/'),'Ã§0','.'),'Ã§1','-'),'Ã§Ã§','Ã§');
END;
$BODY$ LANGUAGE plpgsql IMMUTABLE;
SELECT formatPath('packages/edit-post/src/store/test/selectors.js');
DELETE FROM calls;
INSERT INTO CALLS (origin, path, sl, sc, el, ec, session, line, params) VALUES
('test1', formatPath('packages/edit-post/src/store/test/selectors.js'), 205, 40, 211, 3, -5375, 1, NULL),
('test1', formatPath('packages/edit-post/src/store/selectors.js'), 111, 7, 113, 1, -5375, 2, '["[Object]", "post-status"]'),
('test1', formatPath('packages/scripts/config/global-setup.js'), 70, 11, 76, 1, -5375, 3, NULL),
('test1', 'packages.scripts.config.globalÃ§1setupÃ§0ts', 70, 11, 76, 1, -5377, 3, NULL),
('test1', formatPath('packages/blocks/src/api/raw-handling/test/figure-content-reducer.js'), 35, 36, 40, 2, -5374, 1, NULL);
SELECT formatPath(path) FROM calls;
#+END_SRC

#+NAME: Initial requests
#+BEGIN_SRC sql
CREATE OR REPLACE FUNCTION public.myreq(initPath text)
 RETURNS TABLE(init text, p text, t bigint) AS $BODY$
DECLARE
    chunk int[];
    n int;
BEGIN
    n:=1;
    CREATE TEMP TABLE accTable (n int, hash text, session int, ori int, moves text) on commit drop;
    INSERT INTO accTable (hash, n, session, ori, moves)
    SELECT n, MD5(formatPath(path)),
           calls.session, line,''
    FROM CALLS
    WHERE path @> formatPath(initPath);

    CREATE TEMP TABLE groupTable (n int, hash text, pocc bigint, tocc bigint) on commit drop;
    INSERT INTO groupTable (n, hash, pocc, tocc)
    SELECT (accTable.n, accTable.hash,
           COUNT(SIGN(session)>0),
           COUNT(SIGN(session)<0)
    FROM accTable
    GROUP BY accTable.n, accTable.hash;

    INSERT INTO groupTable (n, hash, p, t)
    SELECT (n, hash,
           CASE WHEN SIGN(session)>0 THEN 'prod' ELSE 'test' END,
           COUNT(*)
    FROM accTable
    GROUP BY n, hash, SIGN(session);

    n:=n+1
    INSERT INTO accTable (hash, n, session, ori, moves)
    SELECT n, MD5(formatPath(path)+hash),
    accTable.session, accTable.ori, CONCAT(moves,'p')
    FROM CALLS, accTable
    WHERE accTable.session = calls.session
    AND ori-1 = line

    INSERT INTO accTable (n, hash, session, ori, moves)
    SELECT n, MD5(hash+formatPath(path)),
    accTable.session, accTable.ori, CONCAT(moves,'n')
    FROM CALLS, accTable
    WHERE accTable.session = calls.session
    AND ori+1 = line

    LOOP
       n:=n+1
       INSERT INTO accTable (hash, n, session, ori, moves)
       SELECT n, hash+formatPath(path),
       accTable.session, accTable.ori , CONCAT(moves,'n')
       FROM CALLS, accTable
       WHERE
       (n%2 = 0 AND )
       ;


       WHEN ????
    END

    RETURN QUERY SELECT * FROM groupTable;
END;
$BODY$ LANGUAGE plpgsql;
SELECT * FROM myreq('packages/edit-post/src/store/selectors.js');
#+END_SRC
#+NAME: v2
#+BEGIN_SRC sql
DROP FUNCTION public.myreq;
CREATE OR REPLACE FUNCTION public.myreq(initPath text)
 RETURNS TABLE(n int, hash text, pocc bigint, tocc bigint) AS $BODY$
#variable_conflict use_variable
DECLARE
    chunk int[];
    n int;
BEGIN
    n:=1;
    CREATE TEMP TABLE accTable (n int NOT NULL, hash text, session int, ori int, moves text) on commit drop;
    INSERT INTO accTable (n, hash, session, ori, moves)
    SELECT n, MD5(formatPath(path)),
           calls.session, line,''
    FROM CALLS
    WHERE path @> formatPath(initPath);

    CREATE TEMP TABLE groupTable (n int, hash text, pocc bigint, tocc bigint) on commit drop;
    INSERT INTO groupTable (n, hash, pocc, tocc)
    SELECT a.n, a.hash,
           SUM((SIGN(a.session)>0)::int),
           SUM((SIGN(a.session)<0)::int)
    FROM accTable a
    GROUP BY a.n, a.hash;

    n:= n + 1;
    -- move to previous line, n=2
    INSERT INTO accTable (n, hash, session, ori, moves)
    SELECT n, MD5(CONCAT(formatPath(c.path),a.hash)),
    a.session, a.ori, CONCAT(a.moves,'p')
    FROM calls c, accTable a
    WHERE a.session = c.session
    AND a.ori-1 = c.line
    AND initPath != formatPath(c.path);

    -- move to next line, n=2
    INSERT INTO accTable (n, hash, session, ori, moves)
    SELECT n, MD5(CONCAT(a.hash,formatPath(c.path))),
    a.session, a.ori, CONCAT(a.moves,'n')
    FROM calls c, accTable a
    WHERE a.session = c.session
    AND a.ori+1 = c.line;

    LOOP

      INSERT INTO groupTable (n, hash, pocc, tocc)
      SELECT a.n, a.hash,
            SUM((SIGN(a.session)>0)::int),
            SUM((SIGN(a.session)<0)::int)
      FROM accTable a
      WHERE n = a.n
      GROUP BY a.n, a.hash;

      EXIT WHEN n >= 3;


      n:= n + 1;
      -- move to previous line, n=2
      INSERT INTO accTable (n, hash, session, ori, moves)
      SELECT n, MD5(CONCAT(formatPath(c.path),a.hash)),
      a.session, a.ori, CONCAT(a.moves,'p')
      FROM calls c, accTable a
      WHERE n-1 = a.n
      AND a.session = c.session
      AND a.ori-1 = c.line
      AND (n%2=0 OR RIGHT(a.moves, 1)='p')
      AND initPath != formatPath(c.path);

      -- move to next line, n=2
      INSERT INTO accTable (n, hash, session, ori, moves)
      SELECT n, MD5(CONCAT(a.hash,formatPath(c.path))),
      a.session, a.ori, CONCAT(a.moves,'n')
      FROM calls c, accTable a
      WHERE n-1 = a.n
      AND a.session = c.session
      AND a.ori+1 = c.line
      AND (RIGHT(a.moves, 1)='n' OR n%2=1);

    END LOOP;

    RETURN QUERY SELECT g.n, a.session, a.ori-(CHAR_LENGTH(a.moves) - CHAR_LENGTH(REPLACE(a.moves, 'p', ''))), g.pocc, g.tocc
    FROM   groupTable g
    CROSS  JOIN LATERAL (
      SELECT a.session, a.ori, a.moves
      FROM   accTable a
      WHERE  g.n = a.n AND g.hash = a.hash         -- lateral reference
      LIMIT  1
      ) a;

END;
$BODY$ LANGUAGE plpgsql;
SELECT * FROM myreq('packages/hooks/src/createCurrentHook.js');
#+END_SRC
#+NAME:v3
#+BEGIN_SRC sql
CREATE OR REPLACE FUNCTION public.formatPath(s char)
 RETURNS ltree AS $BODY$
BEGIN
    return text2ltree(REPLACE(REPLACE(REPLACE(REPLACE(s,'Ã§','Ã§Ã§'),'-','Ã§1'),'.','Ã§0'),'/','.'));
END;
$BODY$ LANGUAGE plpgsql IMMUTABLE;
CREATE OR REPLACE FUNCTION public.formatPath(l ltree)
 RETURNS char AS $BODY$
BEGIN
    return REPLACE(REPLACE(REPLACE(REPLACE(ltree2text(l),'.','/'),'Ã§0','.'),'Ã§1','-'),'Ã§Ã§','Ã§');
END;
$BODY$ LANGUAGE plpgsql IMMUTABLE;
CREATE OR REPLACE FUNCTION public.(l ltree)
 RETURNS char AS $BODY$
BEGIN
    return REPLACE(REPLACE(REPLACE(REPLACE(ltree2text(l),'.','/'),'Ã§0','.'),'Ã§1','-'),'Ã§Ã§','Ã§');
END;
$BODY$ LANGUAGE plpgsql IMMUTABLE;
DROP FUNCTION public.myreq;
CREATE OR REPLACE FUNCTION public.myreq(initPath text)
 RETURNS TABLE(n int, session int, left int, pocc bigint, tocc bigint) AS $BODY$
#variable_conflict use_variable
DECLARE
    chunk int[];
    n int;
BEGIN
    n:=1;
    CREATE TEMP TABLE accTable (n int NOT NULL, hash text, session int, ori int, moves text) on commit drop;
    INSERT INTO accTable (n, hash, session, ori, moves)
    SELECT n, MD5(formatPath(path)),
           calls.session, line,''
    FROM CALLS
    WHERE path @> formatPath(initPath);

    CREATE TEMP TABLE groupTable (n int, hash text, pocc bigint, tocc bigint) on commit drop;
    INSERT INTO groupTable (n, hash, pocc, tocc)
    SELECT a.n, a.hash,
           SUM((SIGN(a.session)>0)::int),
           SUM((SIGN(a.session)<0)::int)
    FROM accTable a
    GROUP BY a.n, a.hash;
    
    n:= n + 1;
    -- move to previous line, n=2
    INSERT INTO accTable (n, hash, session, ori, moves)
    SELECT n, MD5(CONCAT(formatPath(c.path),a.hash)),
    a.session, a.ori, CONCAT(a.moves,'p')
    FROM calls c, accTable a
    WHERE a.session = c.session
    AND a.ori-1 = c.line
    AND NOT (formatPath(initPath) @> c.path);
    
    -- move to next line, n=2
    INSERT INTO accTable (n, hash, session, ori, moves)
    SELECT n, MD5(CONCAT(a.hash,formatPath(c.path))),
    a.session, a.ori, CONCAT(a.moves,'n')
    FROM calls c, accTable a
    WHERE n-1 = a.n
    AND a.session = c.session
    AND a.ori+1 = c.line;
    
    LOOP
    
      INSERT INTO groupTable (n, hash, pocc, tocc)
      SELECT a.n, a.hash,
            SUM((SIGN(a.session)>0)::int),
            SUM((SIGN(a.session)<0)::int)
      FROM accTable a
      WHERE n = a.n
      GROUP BY a.n, a.hash;

      EXIT WHEN n >= 4;

      n:= n + 1;
      -- move to previous line, n=2
      INSERT INTO accTable (n, hash, session, ori, moves)
      SELECT n, MD5(CONCAT(formatPath(c.path),a.hash)),
      a.session, a.ori, CONCAT(a.moves,'p')
      FROM calls c, accTable a
      WHERE n-1 = a.n
      AND a.session = c.session
      AND a.ori-1 = c.line
      AND (n%2=0 OR RIGHT(a.moves, 1)='p')
      AND NOT (formatPath(initPath) @> c.path);

      -- move to next line, n=2
      INSERT INTO accTable (n, hash, session, ori, moves)
      SELECT n, MD5(CONCAT(a.hash,formatPath(c.path))),
      a.session, a.ori, CONCAT(a.moves,'n')
      FROM calls c, accTable a
      WHERE n-1 = a.n
      AND a.session = c.session
      AND a.ori+1 = c.line
      AND (n%2=1 OR RIGHT(a.moves, 1)='n');

    END LOOP;

     RETURN QUERY SELECT g.n, a.session, a.ori-(CHAR_LENGTH(a.moves) - CHAR_LENGTH(REPLACE(a.moves, 'p', ''))), g.pocc, g.tocc
     FROM   groupTable g
     CROSS  JOIN LATERAL (
      SELECT a.session, a.ori, a.moves
      FROM   accTable a
      WHERE  g.n = a.n AND g.hash = a.hash         -- lateral reference
      LIMIT  1
      ) a;

END;
$BODY$ LANGUAGE plpgsql;
SELECT * FROM myreq('packages/hooks/src/createCurrentHook.js');
#+END_SRC
#+NAME: v3 with fct position and fixed moves
#+BEGIN_SRC sql
CREATE OR REPLACE FUNCTION public.formatPath(s char)
 RETURNS ltree AS $BODY$
BEGIN
    return text2ltree(REPLACE(REPLACE(REPLACE(REPLACE(s,'Ã§','Ã§Ã§'),'-','Ã§1'),'.','Ã§0'),'/','.'));
END;
$BODY$ LANGUAGE plpgsql IMMUTABLE;
CREATE OR REPLACE FUNCTION public.formatPath(l ltree)
 RETURNS char AS $BODY$
BEGIN
    return REPLACE(REPLACE(REPLACE(REPLACE(ltree2text(l),'.','/'),'Ã§0','.'),'Ã§1','-'),'Ã§Ã§','Ã§');
END;
$BODY$ LANGUAGE plpgsql IMMUTABLE;

DROP FUNCTION public.myreq;
CREATE OR REPLACE FUNCTION public.myreq(initPath text, sl int, sc int, el int, ec int,max_n int)
 RETURNS TABLE(n int, hash text, session int, left int, pocc bigint, tocc bigint) AS $BODY$
#variable_conflict use_variable
DECLARE
    chunk int[];
    n int;
    origin char(10);
BEGIN
    origin:='gutenberg';
    n:=1;
    CREATE TEMP TABLE accTable (n int NOT NULL, hash text, session int, "left" int, isLastPrev boolean, ori int, 
                                PRIMARY KEY (n, session, "left", hash)) on commit drop;
    CREATE index ON accTable(n, hash);
    
    INSERT INTO accTable (n, hash, session, "left", isLastPrev, ori)
    SELECT n, MD5(CONCAT(formatPath(c.path),c.sl,c.sc,c.el,c.ec)),
           c.session, c.line, false, 0
    FROM CALLS c
    WHERE origin = c.origin
    AND path @> formatPath(initPath)
    AND sl = c.sl
    AND sc = c.sc
    AND el = c.el
    AND ec = c.ec;

    CREATE TEMP TABLE groupTable (n int, hash text, pocc bigint, tocc bigint,
                                  PRIMARY KEY (n, hash)) on commit drop;
    INSERT INTO groupTable (n, hash, pocc, tocc)
    SELECT a.n, a.hash,
           SUM((SIGN(a.session)>0)::int),
           SUM((SIGN(a.session)<0)::int)
    FROM accTable a
    GROUP BY a.n, a.hash;
    
    n:= n + 1;
    -- move to previous line, n=2
    INSERT INTO accTable (n, hash, session, "left", isLastPrev, ori)
    SELECT n, MD5(CONCAT(formatPath(c.path),c.sl,c.sc,c.el,c.ec,a.hash)),
    a.session, a."left"-1, true, a.ori+1
    FROM accTable a, calls c
    WHERE n-1 = a.n
    AND a.session = c.session
    AND a.left-1 = c.line
    AND origin = c.origin
    AND NOT (
        formatPath(initPath) @> c.path
        AND sl = c.sl
        AND sc = c.sc
        AND el = c.el
        AND ec = c.ec);
    
    -- move to next line, n=2
    INSERT INTO accTable (n, hash, session, "left", isLastPrev, ori)
    SELECT n, MD5(CONCAT(a.hash,formatPath(c.path),c.sl,c.sc,c.el,c.ec)),
    a.session, a.left, false, a.ori
    FROM accTable a, calls c
    WHERE n-1 = a.n
    AND origin = c.origin
    AND a.session = c.session
    AND a.left+(n-1) = c.line;
    
    LOOP
    
      INSERT INTO groupTable (n, hash, pocc, tocc)
      SELECT a.n, a.hash,
            SUM((SIGN(a.session)>0)::int),
            SUM((SIGN(a.session)<0)::int)
      FROM accTable a
      WHERE n = a.n
      GROUP BY a.n, a.hash;

      EXIT WHEN n >= max_n;

      n:= n + 1;
      ANALYZE accTable;
      -- move to previous line, n=2
      INSERT INTO accTable (n, hash, session, "left", isLastPrev, ori)
      SELECT n, MD5(CONCAT(formatPath(c.path),c.sl,c.sc,c.el,c.ec,a.hash)),
      a.session, a.left-1, true, a.ori+1
      FROM accTable a, groupTable g, calls c
      WHERE n-1 = a.n
      AND n-1 = g.n
      AND a.hash = g.hash
      AND origin = c.origin
      AND a.session = c.session
      AND a.left-1 = c.line
      AND (n%2=0 OR a.isLastPrev)
      AND NOT (formatPath(initPath) @> c.path
        AND sl = c.sl
        AND sc = c.sc
        AND el = c.el
        AND ec = c.ec);

      -- move to next line, n=2
      INSERT INTO accTable (n, hash, session, "left", isLastPrev, ori)
      SELECT n, MD5(CONCAT(a.hash,formatPath(c.path),c.sl,c.sc,c.el,c.ec)),
      a.session, a.left, false, a.ori
      FROM accTable a, groupTable g, calls c
      WHERE n-1 = a.n
      AND n-1 = g.n
      AND a.hash = g.hash
      AND origin = c.origin
      AND a.session = c.session
      AND a.left+(n-1) = c.line
      AND (n%2=1 OR NOT a.isLastPrev);

    END LOOP;

     RETURN QUERY SELECT g.n, g.hash, a.session, a.left, g.pocc, g.tocc
     FROM   groupTable g
     CROSS  JOIN LATERAL (
      SELECT a.session, a.left
      FROM   accTable a
      WHERE  g.n = a.n AND g.hash = a.hash         -- lateral reference
      LIMIT  1
      ) a;

END;
$BODY$ LANGUAGE plpgsql;
SELECT c.*, g.*
FROM myreq('packages/data/src/components/with-select/index.js',53,71,206,1,5) as g,
     calls c
WHERE 'gutenberg' = c.origin
AND c.session = g.session
AND line >= g.left
AND line < g.left+g.n
ORDER BY g.n, g.hash,g.session,c.line;
#+END_SRC
#+NAME: v3 using some heuristics
#+BEGIN_SRC sql
CREATE OR REPLACE FUNCTION public.formatPath(s char)
 RETURNS ltree AS $BODY$
BEGIN
    return text2ltree(REPLACE(REPLACE(REPLACE(REPLACE(s,'Ã§','Ã§Ã§'),'-','Ã§1'),'.','Ã§0'),'/','.'));
END;
$BODY$ LANGUAGE plpgsql IMMUTABLE;
CREATE OR REPLACE FUNCTION public.formatPath(l ltree)
 RETURNS char AS $BODY$
BEGIN
    return REPLACE(REPLACE(REPLACE(REPLACE(ltree2text(l),'.','/'),'Ã§0','.'),'Ã§1','-'),'Ã§Ã§','Ã§');
END;
$BODY$ LANGUAGE plpgsql IMMUTABLE;

DROP FUNCTION public.myreq;
CREATE OR REPLACE FUNCTION public.myreq(initPath text, sl int, sc int, el int, ec int,max_n int)
 RETURNS TABLE(n int, hash text, session int, left int, pocc bigint, tocc bigint) AS $BODY$
#variable_conflict use_variable
DECLARE
    chunk int[];
    n int;
    origin char(10);
BEGIN
    origin:='gutenberg';
    n:=1;
    CREATE TEMP TABLE accTable (n int NOT NULL, hash text, session int, "left" int, isLastPrev boolean, ori int, 
                                PRIMARY KEY (n, session, "left", hash)) on commit drop;
    CREATE index ON accTable(n, hash);
    
    INSERT INTO accTable (n, hash, session, "left", isLastPrev, ori)
    SELECT n, MD5(CONCAT(formatPath(c.path),c.sl,c.sc,c.el,c.ec)),
           c.session, c.line, false, 0
    FROM CALLS c
    WHERE origin = c.origin
    AND path @> formatPath(initPath)
    AND sl = c.sl
    AND sc = c.sc
    AND el = c.el
    AND ec = c.ec;

    CREATE TEMP TABLE groupTable (n int, hash text, pocc bigint, tocc bigint,
                                  PRIMARY KEY (n, hash)) on commit drop;
    INSERT INTO groupTable (n, hash, pocc, tocc)
    SELECT a.n, a.hash,
           SUM((SIGN(a.session)>0)::int),
           SUM((SIGN(a.session)<0)::int)
    FROM accTable a
    GROUP BY a.n, a.hash;
    
    n:= n + 1;
    -- move to previous line, n=2
    INSERT INTO accTable (n, hash, session, "left", isLastPrev, ori)
    SELECT n, MD5(CONCAT(formatPath(c.path),c.sl,c.sc,c.el,c.ec,a.hash)),
    a.session, a."left"-1, true, a.ori+1
    FROM accTable a, (SELECT * FROM groupTable g ORDER BY g.pocc DESC, g.n DESC, g.tocc LIMIT 4*ceil(log(n,n))) g, calls c
    WHERE n-1 = a.n
    AND n-1 = g.n
    AND a.hash = g.hash
    AND a.session = c.session
    AND a.left-1 = c.line
    AND origin = c.origin
    AND NOT (
        formatPath(initPath) @> c.path
        AND sl = c.sl
        AND sc = c.sc
        AND el = c.el
        AND ec = c.ec);
    
    -- move to next line, n=2
    INSERT INTO accTable (n, hash, session, "left", isLastPrev, ori)
    SELECT n, MD5(CONCAT(a.hash,formatPath(c.path),c.sl,c.sc,c.el,c.ec)),
    a.session, a.left, false, a.ori
    FROM accTable a, (SELECT * FROM groupTable g ORDER BY g.pocc DESC, g.n DESC, g.tocc LIMIT 4*ceil(log(n,n))) g, calls c
    WHERE n-1 = a.n
    AND n-1 = g.n
    AND a.hash = g.hash
    AND origin = c.origin
    AND a.session = c.session
    AND a.left+(n-1) = c.line;
    
    LOOP
    
      INSERT INTO groupTable (n, hash, pocc, tocc)
      SELECT a.n, a.hash,
            SUM((SIGN(a.session)>0)::int),
            SUM((SIGN(a.session)<0)::int)
      FROM accTable a
      WHERE n = a.n
      GROUP BY a.n, a.hash;

      EXIT WHEN n >= max_n;

      n:= n + 1;
      ANALYZE accTable;
      -- move to previous line, n=2
      INSERT INTO accTable (n, hash, session, "left", isLastPrev, ori)
      SELECT n, MD5(CONCAT(formatPath(c.path),c.sl,c.sc,c.el,c.ec,a.hash)),
      a.session, a.left-1, true, a.ori+1
      FROM accTable a, (SELECT * FROM groupTable g ORDER BY g.pocc DESC, g.n DESC, g.tocc LIMIT 4*ceil(log(n,n))) g, calls c
      WHERE n-1 = a.n
      AND n-1 = g.n
      AND a.hash = g.hash
      AND origin = c.origin
      AND a.session = c.session
      AND a.left-1 = c.line
      AND (n%2=0 OR a.isLastPrev)
      AND NOT (formatPath(initPath) @> c.path
        AND sl = c.sl
        AND sc = c.sc
        AND el = c.el
        AND ec = c.ec);

      -- move to next line, n=2
      INSERT INTO accTable (n, hash, session, "left", isLastPrev, ori)
      SELECT n, MD5(CONCAT(a.hash,formatPath(c.path),c.sl,c.sc,c.el,c.ec)),
      a.session, a.left, false, a.ori
      FROM accTable a, (SELECT * FROM groupTable g ORDER BY g.pocc DESC, g.n DESC, g.tocc LIMIT 4*ceil(log(n,n))) g, calls c
      WHERE n-1 = a.n
      AND n-1 = g.n
      AND a.hash = g.hash
      AND origin = c.origin
      AND a.session = c.session
      AND a.left+(n-1) = c.line
      AND (n%2=1 OR NOT a.isLastPrev);

    END LOOP;

     RETURN QUERY SELECT g.n, g.hash, a.session, a.left, g.pocc, g.tocc
     FROM   groupTable g
     CROSS  JOIN LATERAL (
      SELECT a.session, a.left
      FROM   accTable a
      WHERE  g.n = a.n AND g.hash = a.hash         -- lateral reference
      LIMIT  1
      ) a;

END;
$BODY$ LANGUAGE plpgsql;
SELECT c.*, g.*
FROM myreq('packages/data/src/components/with-select/index.js',53,71,206,1,70) as g,
     calls c
WHERE 'gutenberg' = c.origin
AND c.session = g.session
AND line >= g.left
AND line < g.left+g.n
ORDER BY g.n, g.hash,g.session,c.line;
#+END_SRC
** [2019-06-13 Thu]
*** Plan
**** instrumentation
***** dynamic instrumentation
There is 2 main possibilities to instrument javascript in browser at compile time.
#+BEGIN_EXAMPLE

    --------<script src="xxxxx.js"></script>----<script src="xxxx.com/xxxx.js"></script>------<script>xxxxxxxxxxx</script>------------------------------------------>
             \                            /      \                                    /              \          /
              \                         (*)       \                                  /                +-(6)(*)-+
DOM parsing   (1)                       /         (4)                               /
                \                      /            \                              /
          -------v--------------------^--------------\----------------------------/----
                  \                  /                \                          /
HTTP PACKETS      (2)              (3)                 \                        /
                    \              /                    \                      /
          -----------\------------/----------------------\--------------------/---------------------------
                      \          /                        \                  /
                                                           \----------(5)---/
                                                              \    /
#+END_EXAMPLE
****** Mutation Observer
Using a mutation observer, it allow us to modify scripts added on the page during DOM parsing
This mutation Observer can be directly included in the original page as the first script balise,
on dynamically added to pages with an browser extension
****** Intercepting http requests
Use the Fetch domain of Devtools API (through puppeteer),
to intercept and modify incoming responses to scripts requested.
Make use of the browser cache, js parsing to instrument code is done in the puppeteer (nodejs) process, relieving browser of some stress
Don't work on inline scripts at this point (maybe intercepting html request and parsing the DOM)
***** instrumentation at compile time
**** Venn diag. with symbols of functions
#+BEGIN_EXAMPLE

  +------------------------------------------------------+
  | instrumented                                         |
  | symbols +------------+----------+--------------+     |
  |         |            | prod     |              |     |
  |         |            | & test   |              |     |
  |         |  test      |          |    prod      |     |
  |         |  & -prod   |          |    & -test   |     |
  |         |            |          |              |     |
  |         |            |          |              |     |
  |         +------------+----------+--------------+     |
  |                                                      |
  +------------------------------------------------------+

#+END_EXAMPLE
**** Venn diag. with function's symbols and parameters
#+BEGIN_EXAMPLE

            +------------+----------+--------------+
            |            | prod     |              |
            |            | & test   |              |
            |  test      |          |    prod      |
            |  & -prod   |          |    & -test   |
            |            |          |              |
            |            |          |              |
            +------------+----------+--------------+

#+END_EXAMPLE
**** distribution of calls on dataset
#+BEGIN_SRC
production/test calls sorted by number of occurences of production.
y axis show # of calls
x axis show calls, only some interesting calls are visible.
#+END_SRC
[[file:plots/distrib.png]]
**** DEFERRED distribution of calls with parameters on dataset :noexport:
     CLOSED: [2019-06-20 Thu 16:50] to much points to plot
#+BEGIN_SRC
production/test calls sorted by number of occurences of production.
y axis show # of calls
x axis show calls+parameters, only some interesting calls and parameters are visible.
#+END_SRC
** [2019-06-14 Fri]
*** STARTED read [[http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=877A01775995830BB127116FB11BAB49?doi=10.1.1.323.3411&rep=rep1&type=pdf]]
*** Night idea
recursively compute ngrams and compress previously compared ngrams (parts)
#+BEGIN_SRC sql
CREATE TEMPORARY TABLE aaa(
  n int,
  hash int,
  session int,
  prevl int,
  nextl int
  )
#+END_SRC
#+BEGIN_EXAMPLE
1  2    3      4
x ax_ _11c_ _b111__
            __111b_
      b11__ a222___
            _222c__ -
  _xc _a44_ _b333__ --
            __333b_ -
      __44c __a444_ -
            ___444c
x ax_ _11a_ _b555__
            __555a_
      b11__ _222a__
            c222___
  _xa _a55_ _b666__
            __666a_
      __55a ___777c
            __a777_
x bx_ _22c_ _______
  _xc _b44_ _______
x ax_ _11a_ _______
  _xa _a55_ __222__
x cx_ _33c_ __444__
  _xc _c44_ __444__
x cx_ _33c_ __444__
  _xc _c44_ __444__
x bx_ _22b_ __555__
  _xb _b66_ __555__
#+END_EXAMPLE
** [2019-06-18 Tue]
*** DONE recreate test traces with the new version of gutenberg (5.3)
I implemented an environment that instantiate for each test file an array in the global scope then at the end write it on disk.
*** TODO plot venn diag between prod traces and/or tests
use distribution data?
** [2019-06-19 Wed]
*** DONE plot distribution on subsets of gutenberg
     CLOSED: [2019-06-20 Thu 16:36]
     use =npm run build && node out/makerequests.pg.js | python ../plots/main.py multi-dist line -o ../plots/multidistrib_root2.png= in behaviour-client
*** DONE use https://github.com/Jacarte/bufferedDTW/blob/master/docs/ngram.md
*** STARTED read [[https://cs.uwaterloo.ca/~m2nagapp/courses/CS846/1171/papers/hindle_icse12.pdf][Lossless compaction of model execution traces]]
- xDSML -> models on xDSL
- my traces are only a list of transitions compared to the heterogeneous traces targeted by this paper
*** DONE look at [[https://livablesoftware.com/conflictjs-javascript-libraries-conflicts/]]
    CLOSED: [2019-06-20 Thu 11:03]
Out of scope for the internship but the instrumentation tool could be modified to get those kinds of events (assignments on global scope things)
- One way is to wrap global variables with Proxies
- Could also monitor assignments and filter those accessible from global scope :: I mean do the assignment normally then check is the left hand side can be accessed from a specially made function (that live in the global scope).
*** DONE put links in references
    CLOSED: [2019-06-19 Wed 14:44]
*** DEFERRED try to correct method on the remark of Benoit
    CLOSED: [2019-06-19 Wed 16:04] not possible in my time frame
Benoit Gave me a good remark on my algorithm, telling that it does not compress repetitive patterns.
Like aaaaa should become a+ and abababab should become (ab)+ and more like that.
But taking n=2 like in the first paper makes is only able to compress some patterns.
For now I have some intuitions on the way of doing it.
** [2019-06-20 Thu]
*** TODO read [[http://scholar.google.com/scholar_url?url=https://repositories.lib.utexas.edu/bitstream/handle/2152/74915/DEMIR-THESIS-2018.pdf%3Fsequence%3D1&hl=en&sa=X&d=1403606065224085342&scisig=AAGBfm2v_GD75ccW2YmX0f0YtXa-BA2HfA&nossl=1&oi=scholaralrt&hist=dJQf4SYAAAAJ:5158978984045542397:AAGBfm2WcvuDR2BwMr2WgI3aikY9NcnSzw][Test-splitter: creating unit tests from system tests with different input combinations]]
does not load...
*** TODO plot distribution of interesting packages with more than 1-gram
- multiple standard request?
- async requests on temporary table that is at the same time improved.
*** DONE sql count number of different session where symbol appear
    CLOSED: [2019-06-29 Sat 00:48]
#+BEGIN_SRC sql
array_length(ARRAY_AGG(DISTINCT (CASE WHEN session>0 THEN session ELSE NULL END)),1)
#+END_SRC
*** TODO end query using a timeout
https://stackoverflow.com/questions/9063402/get-execution-time-of-postgresql-query
#+BEGIN_SRC sql
DECLARE
StartTime timestamptz;
  EndTime timestamptz;
  Delta double precision;
BEGIN
  StartTime := clock_timestamp();
  --PERFORM YOUR QUERY HERE;
  EndTime := clock_timestamp();
  Delta := 1000 * ( extract(epoch from EndTime) - extract(epoch from StartTime) );
  RAISE NOTICE 'Duration in millisecs=%', Delta;
#+END_SRC
*** TODO put temporary tables of my pg function in global scope
#+BEGIN_SRC sql
-- contain all processed ngrams
CREATE TABLE accTable (n int NOT NULL, hash text NOT NULL, session int NOT NULL, "left" int NOT NULL, isLastPrev boolean NOT NULL, ori int NOT NULL, 
                       PRIMARY KEY (n, session, "left"));
CREATE index ON accTable(n, hash);
-- if you want to know the number of basic symbols started to be processed, count number of distinct 1,1-gram in accTable
-- if you want to find the row of a particular function search for (1, MD5(CONCAT(formatPath(c.path),c.sl,c.sc,c.el,c.ec))) in accTable
-- you can search for missing ngrams looking for gaps in (n, session, left) when sorted
-- if you want to process a new ngram in the database you need to make apply the algorithm starting from the left symbol
-- for any given ngram you can fin how it was contructed looking at the symbol pointed by session,left+ori

-- contain statistics on ngrams, such as occurences in tests and production
CREATE TABLE groupTable (path ltree NOT NULL, sl int NOT NULL, sc int NOT NULL, el int NOT NULL, ec int NOT NULL, n int NOT NULL, hash text NOT NULL, pocc bigint NOT NULL, tocc bigint NOT NULL,
                              PRIMARY KEY (path, sl, sc, el, ec, n, hash));
-- each indexed symbols statitics are accessible through the given symbol then the ngram size
-- so the size of this table should be proportional to the number of indexed symbols and the number of ngram mined through accTable

-- Procedure to instanciate a 1-gram in accTable
-- Caution it shouldn't be used anymore (useless) because entirely computed from calls table and statics in groupTable
INSERT INTO accTable (n, hash, session, "left", isLastPrev, ori)
SELECT n, MD5(CONCAT(formatPath(c.path),c.sl,c.sc,c.el,c.ec)),
        c.session, c.line, false, 0
FROM CALLS c
WHERE origin = c.origin
AND path @> formatPath(initPath)
AND sl = c.sl
AND sc = c.sc
AND el = c.el
AND ec = c.ec;

CREATE OR REPLACE FUNCTION public.get2gram(initPath text, sl int, sc int, el int, ec int)
 RETURNS TABLE(n int, hash text, session int, left int, pocc bigint, tocc bigint) AS $BODY$
#variable_conflict use_variable
DECLARE
  n int;
  origin text;
BEGIN
  origin:='gutenberg';
  n:=1;

  WITH a as (
  -- instanciate 1-gram
  SELECT n, MD5(CONCAT(formatPath(c.path),c.sl,c.sc,c.el,c.ec)),
          c.session, c.line, false, 0
  FROM CALLS c
  WHERE origin = c.origin
  AND path @> formatPath(initPath)
  AND sl = c.sl
  AND sc = c.sc
  AND el = c.el
  AND ec = c.ec)
  -- Procedure to instanciate statics of 1-gram in groupTable
  INSERT INTO groupTable (path, sl, sc, el, ec, n, hash, pocc, tocc)
  SELECT initPath, sl, sc, el, ec, a.n, a.hash,
          SUM((SIGN(a.session)>0)::int),
          SUM((SIGN(a.session)<0)::int)
  FROM a
  GROUP BY a.n, a.hash;

  n:= n + 1; -- n = 2
  WITH g AS (
    SELECT * FROM groupTable g 
    ORDER BY g.pocc DESC, g.n DESC, g.tocc 
    --LIMIT 4*ceil(log(n,n))
  ), a AS (
  -- move to previous line, n=2
  INSERT INTO accTable (n, hash, session, "left", isLastPrev, ori)
  SELECT n, MD5(CONCAT(formatPath(c.path),c.sl,c.sc,c.el,c.ec,a.hash)),
  a.session, a."left"-1, true, a.ori+1
  FROM accTable a,  g, calls c
  WHERE -- n-1 = a.n AND n-1 = g.n AND 
  a.hash = g.hash
  AND a.session = c.session
  AND a.left-1 = c.line
  AND origin = c.origin
  AND NOT (
      formatPath(initPath) @> c.path
      AND sl = c.sl
      AND sc = c.sc
      AND el = c.el
      AND ec = c.ec);
  UNION ALL
  -- move to next line, n=2
  SELECT n, MD5(CONCAT(a.hash,formatPath(c.path),c.sl,c.sc,c.el,c.ec)),
  a.session, a.left, false, a.ori
  FROM accTable a, g, calls c
  WHERE --n-1 = a.n AND n-1 = g.n
  a.hash = g.hash
  AND origin = c.origin
  AND a.session = c.session
  AND a.left+(n-1) = c.line)
  
  INSERT INTO groupTable (n, hash, pocc, tocc)
  SELECT a.n, a.hash,
         SUM((SIGN(a.session)>0)::int),
         SUM((SIGN(a.session)<0)::int)
  FROM a

  RETURN QUERY SELECT g.n, g.hash, a.session, a.left, g.pocc, g.tocc
  FROM   groupTable g
  CROSS  JOIN LATERAL (
  SELECT a.session, a.left
  FROM   accTable a
  WHERE  g.n = a.n AND g.hash = a.hash         -- lateral reference
  LIMIT  1
) a;
END;
$BODY$ LANGUAGE plpgsql;
#+END_SRC
#+NAME: 2gram
#+BEGIN_SRC  sql
CREATE OR REPLACE FUNCTION public.get2gram(initPath text, sl int, sc int, el int, ec int)
 RETURNS TABLE(n int, hash text, session int, left int, pocc bigint, tocc bigint) AS $BODY$
#variable_conflict use_variable
DECLARE
  origin text;
BEGIN
  origin:='gutenberg';

  WITH a1 AS (
    -- get 1-grams of initPath:sl:sc:el:ec
    SELECT MD5(CONCAT(formatPath(c.path),c.sl,c.sc,c.el,c.ec)) as hash,
           c.session as session, c.line as "left"
    FROM CALLS c
    WHERE origin = c.origin
    AND path @> formatPath(initPath)
    AND sl = c.sl
    AND sc = c.sc
    AND el = c.el
    AND ec = c.ec
  ), g1 AS (
    -- Procedure to instanciate statics of 1-gram in groupTable
    INSERT INTO groupTable (path, sl, sc, el, ec, n, hash, pocc, tocc)
    SELECT formatPath(initPath), sl, sc, el, ec, 1, a.hash,
           SUM((SIGN(a.session)>0)::int),
           SUM((SIGN(a.session)<0)::int)
    FROM a1 a
    GROUP BY a.hash
    ON CONFLICT ON CONSTRAINT grouptable_pkey 
    DO UPDATE SET pocc = excluded.pocc, tocc = excluded.tocc
    RETURNING hash, pocc, tocc
  ), a2 AS (
  -- move to previous line, n=2
  INSERT INTO accTable (n, hash, session, "left", isLastPrev, ori)
  SELECT 2, MD5(CONCAT(formatPath(c.path),c.sl,c.sc,c.el,c.ec,a.hash)),
  a.session, a."left"-1, true, 1
  FROM a1 a, g1 g, calls c
  WHERE a.session = c.session
  AND a.left-1 = c.line
  AND origin = c.origin
  AND NOT (
      formatPath(initPath) @> c.path
      AND sl = c.sl
      AND sc = c.sc
      AND el = c.el
      AND ec = c.ec)
  UNION ALL
  -- move to next line, n=2
  SELECT 2, MD5(CONCAT(a.hash,formatPath(c.path),c.sl,c.sc,c.el,c.ec)),
  a.session, a.left, false, 0
  FROM a1 a, g1 g, calls c
  WHERE origin = c.origin
  AND a.session = c.session
  AND a.left+(2-1) = c.line
    ON CONFLICT ON CONSTRAINT acctable_pkey
    DO UPDATE 
    SET ori = excluded.ori, hash = excluded.hash
    WHERE accTable.ori>excluded.ori
  RETURNING *
  )
  INSERT INTO groupTable (path, sl, sc, el, ec, n, hash, pocc, tocc)
    SELECT formatPath(initPath), sl, sc, el, ec, 2 as n, a.hash,
         SUM((SIGN(a.session)>0)::int),
         SUM((SIGN(a.session)<0)::int)
  FROM a2 a
  GROUP BY n, a.hash
    ON CONFLICT ON CONSTRAINT grouptable_pkey 
    DO UPDATE SET pocc = excluded.pocc, tocc = excluded.tocc;

  RETURN QUERY SELECT g.n, g.hash, a.session, a.left, g.pocc, g.tocc
  FROM   groupTable g
  CROSS  JOIN LATERAL (
    (SELECT c.session as session, c.line as "left"
    FROM CALLS c
    WHERE origin = c.origin
    AND path @> formatPath(initPath)
    AND sl = c.sl
    AND sc = c.sc
    AND el = c.el
    AND ec = c.ec
    AND MD5(CONCAT(formatPath(c.path),c.sl,c.sc,c.el,c.ec)) = g.hash         -- lateral reference
    LIMIT 1)
  UNION ALL
  SELECT a.session, a.left
  FROM   accTable a, calls c
  WHERE  g.n = a.n AND g.hash = a.hash         -- lateral reference
  LIMIT  1
) a;
END;
$BODY$ LANGUAGE plpgsql;

SELECT c.*, g.*
FROM get2gram('packages/blocks/src/store/selectors.js'::text,115,29,117,4) as g,
     calls c
WHERE 'gutenberg' = c.origin
AND c.session = g.session
AND line >= g.left
AND line < g.left+g.n
ORDER BY g.n, g.hash,g.session,c.line;
#+END_SRC
#+BEGIN_SRC sql
DROP FUNCTION public.get2gram;
DELETE FROM acctable;DELETE FROM grouptable;
CREATE OR REPLACE FUNCTION public.get2gram(initPath text, sl int, sc int, el int, ec int)
 RETURNS TABLE(n int, hash text, session int, left int, pocc bigint, tocc bigint) AS $BODY$
#variable_conflict use_variable
DECLARE
  origin text;
BEGIN
  origin:='gutenberg';

  WITH a1 AS (
    -- get 1-grams of initPath:sl:sc:el:ec
    SELECT MD5(CONCAT(formatPath(c.path),c.sl,c.sc,c.el,c.ec)) as hash,
           c.session as session, c.line as "left"
    FROM CALLS c
    WHERE origin = c.origin
    AND path @> formatPath(initPath)
    AND sl = c.sl
    AND sc = c.sc
    AND el = c.el
    AND ec = c.ec
  ), g1 AS (
    -- Procedure to instanciate statics of 1-gram in groupTable
    INSERT INTO groupTable (path, sl, sc, el, ec, n, hash, pocc, tocc)
    SELECT formatPath(initPath), sl, sc, el, ec, 1, a.hash,
           SUM((SIGN(a.session)>0)::int),
           SUM((SIGN(a.session)<0)::int)
    FROM a1 a
    GROUP BY a.hash
    ON CONFLICT ON CONSTRAINT grouptable_pkey 
    DO UPDATE SET pocc = excluded.pocc, tocc = excluded.tocc
    RETURNING hash, pocc, tocc
  ), a2 AS (
    -- move to previous line, n=2
    INSERT INTO accTable (n, hash, session, "left", isLastPrev, ori)
    SELECT 2, MD5(CONCAT(formatPath(c.path),c.sl,c.sc,c.el,c.ec,a.hash)),
    a.session, a."left"-1, true, 1
    FROM a1 a, g1 g, calls c
    WHERE a.session = c.session
    AND a.left-1 = c.line
    AND origin = c.origin
    AND NOT (
        formatPath(initPath) @> c.path
        AND sl = c.sl
        AND sc = c.sc
        AND el = c.el
        AND ec = c.ec)
    UNION ALL
    -- move to next line, n=2
    SELECT 2, MD5(CONCAT(a.hash,formatPath(c.path),c.sl,c.sc,c.el,c.ec)),
    a.session, a.left, false, 0
    FROM a1 a, g1 g, calls c
    WHERE origin = c.origin
    AND a.session = c.session
    AND a.left+(2-1) = c.line
--      ON CONFLICT ON CONSTRAINT acctable_pkey
--      DO UPDATE 
--      SET ori = excluded.ori, hash = excluded.hash
--      WHERE accTable.ori>excluded.ori
      --need to update group table  (change hash)
    RETURNING *
  )
  INSERT INTO groupTable (path, sl, sc, el, ec, n, hash, pocc, tocc)
  SELECT formatPath(initPath), sl, sc, el, ec, 2 as n, a.hash,
         SUM((SIGN(a.session)>0)::int),
         SUM((SIGN(a.session)<0)::int)
  FROM a2 a
  GROUP BY n, a.hash
    ON CONFLICT ON CONSTRAINT grouptable_pkey 
    DO NOTHING; --UPDATE SET pocc = excluded.pocc, tocc = excluded.tocc;

  RETURN QUERY SELECT g.n, g.hash, a.session, a.left, g.pocc, g.tocc
  FROM   groupTable g
  CROSS  JOIN LATERAL (
  SELECT a.session, a.left
  FROM   accTable a, calls c
  WHERE 
    g.path @> formatPath(initPath)
    AND sl = g.sl
    AND sc = g.sc
    AND el = g.el
    AND ec = g.ec
    AND g.n = a.n AND g.hash = a.hash         -- lateral reference
  ORDER BY c.session, c.line
  LIMIT  1
  ) a
  UNION ALL
  SELECT g.n, g.hash, a.session, a.left, g.pocc, g.tocc
  FROM   groupTable g
  CROSS  JOIN LATERAL (
  SELECT c.session as session, c.line as "left"
    FROM CALLS c
    WHERE g.n=1
    AND g.path @> formatPath(initPath)
    AND sl = g.sl    AND sc = g.sc    AND el = g.el    AND ec = g.ec
    AND origin = c.origin
    AND c.path @> formatPath(initPath)
    AND sl = c.sl    AND sc = c.sc    AND el = c.el    AND ec = c.ec
    ORDER BY c.session, c.line
    LIMIT 1) a;
END;
$BODY$ LANGUAGE plpgsql;

SELECT c.*, g.*
FROM get2gram('packages/hooks/src/createRunHook.js',12,0,71,1) as g,
     calls c
WHERE 'gutenberg' = c.origin
AND c.session = g.session
AND line >= g.left
AND line < g.left+g.n
ORDER BY g.n, g.hash,g.session,c.line;

SELECT c.*, g.*
FROM get2gram('packages/hooks/src/createDoingHook.js',10,0,30,1) as g,
     calls c
WHERE 'gutenberg' = c.origin
AND c.session = g.session
AND line >= g.left
AND line < g.left+g.n
ORDER BY g.n, g.hash,g.session,c.line;
#+END_SRC
*** TODO look at https://wiki.postgresql.org/wiki/Don't_Do_This
** [2019-06-25 Tue]
*** DONE multi2gram
#+BEGIN_SRC sql
DROP FUNCTION public.getngrams;
--DELETE FROM acctable;DELETE FROM grouptable;
CREATE OR REPLACE FUNCTION public.compute2gram(initPath text, sl int, sc int, el int, ec int)
 RETURNS void AS $BODY$
#variable_conflict use_variable
DECLARE
  origin text;
BEGIN
  origin:='gutenberg';

  WITH a1 AS (
    -- get 1-grams of initPath:sl:sc:el:ec
    SELECT MD5(CONCAT(formatPath(c.path),c.sl,c.sc,c.el,c.ec)) as hash,
           c.session as session, c.line as "left"
    FROM CALLS c
    WHERE origin = c.origin
    AND path @> formatPath(initPath)
    AND sl = c.sl
    AND sc = c.sc
    AND el = c.el
    AND ec = c.ec
  ), g1 AS (
    -- Procedure to instanciate statics of 1-gram in groupTable
    INSERT INTO groupTable (origin, path, sl, sc, el, ec, n, hash, shift, pocc, tocc)
    SELECT origin, formatPath(initPath), sl, sc, el, ec, 1, a.hash, 0,
           SUM((SIGN(a.session)>0)::int),
           SUM((SIGN(a.session)<0)::int)
    FROM a1 a
    GROUP BY a.hash
    ON CONFLICT ON CONSTRAINT grouptable_pkey
    DO UPDATE SET pocc = excluded.pocc, tocc = excluded.tocc
    RETURNING pocc, tocc
  ), a2 AS (
    INSERT INTO accTable (origin, n, hash, session, "left", isLastPrev, shift)
    -- move to previous line, n=2
    SELECT origin, 2, MD5(CONCAT(formatPath(c.path),c.sl,c.sc,c.el,c.ec,MD5(CONCAT(formatPath(initPath),sl,sc,el,ec)))) as hash2,
    a.session, a."left"-1, true, 1
    FROM a1 a, g1 g, calls c
    WHERE origin = c.origin
    AND a.session = c.session
    AND a.left-1 = c.line 
    AND NOT (
        formatPath(initPath) <@ c.path
        AND sl = c.sl
        AND sc = c.sc
        AND el = c.el
        AND ec = c.ec)
    UNION ALL
    -- move to next line, n=2
    SELECT origin, 2, MD5(CONCAT(MD5(CONCAT(formatPath(initPath),sl,sc,el,ec)),formatPath(c.path),c.sl,c.sc,c.el,c.ec)) as hash2,
    a.session, a.left, false, 0
    FROM a1 a, g1 g, calls c
    WHERE origin = c.origin
    AND a.session = c.session
    AND a.left+(2-1) = c.line
      ON CONFLICT ON CONSTRAINT acctable_pkey
      DO UPDATE
      SET hash = accTable.hash, shift = LEAST(excluded.shift,accTable.shift)
      --need to update group table  (change hash)
    RETURNING acctable.hash, acctable.session, acctable.shift
  )
  INSERT INTO groupTable (origin, path, sl, sc, el, ec, n, hash, shift, pocc, tocc)
  SELECT origin, formatPath(initPath), sl, sc, el, ec, 2 as n, a.hash, MIN(a.shift),
         SUM((SIGN(a.session)>0)::int),
         SUM((SIGN(a.session)<0)::int)
  FROM a2 a
  WHERE NOT a.hash is NULL
  GROUP BY a.hash
  ON CONFLICT ON CONSTRAINT grouptable_pkey 
  DO UPDATE SET pocc = excluded.pocc, tocc = excluded.tocc;

END;
$BODY$ LANGUAGE plpgsql;

CREATE OR REPLACE FUNCTION public.getngrams(initPath text, sl int, sc int, el int, ec int, max_n smallint)
 RETURNS TABLE(n int, hash text, session int, left int, pocc bigint, tocc bigint) AS $BODY$
#variable_conflict use_variable
DECLARE
  origin text;
  checkpoint_n smallint;
BEGIN
  origin:='gutenberg';
  checkpoint_n := (
    select MAX(g.n)
    from groupTable g
    where origin = g.origin
    AND g.path @> formatPath(initPath)
    AND sl = g.sl
    AND sc = g.sc
    AND el = g.el
    AND ec = g.ec
    GROUP BY g.path, g.sl, g.sc, g.el, g.ec
  );
  IF checkpoint_n is NULL
  THEN
    PERFORM compute2gram(initPath, sl, sc, el, ec);
  END IF;

  RETURN QUERY SELECT g.n, g.hash, a.session, a.left, g.pocc, g.tocc
  FROM   groupTable g
  CROSS  JOIN LATERAL (
  SELECT a.session, a.left
  FROM   accTable a, calls c
  WHERE 
    g.path @> formatPath(initPath)
    AND sl = g.sl
    AND sc = g.sc
    AND el = g.el
    AND ec = g.ec
    AND g.n = a.n AND g.hash = a.hash         -- lateral reference
  --ORDER BY c.session, c.line
  LIMIT  1
  ) a
  UNION ALL
  SELECT g.n, g.hash, a.session, a.left, g.pocc, g.tocc
  FROM   groupTable g
  CROSS  JOIN LATERAL (
  SELECT c.session as session, c.line as "left"
    FROM CALLS c
    WHERE g.n=1
    AND g.path @> formatPath(initPath)
    AND sl = g.sl    AND sc = g.sc    AND el = g.el    AND ec = g.ec
    AND origin = c.origin
    AND c.path @> formatPath(initPath)
    AND sl = c.sl    AND sc = c.sc    AND el = c.el    AND ec = c.ec
    --ORDER BY c.session, c.line
    LIMIT 1) a;
END;
$BODY$ LANGUAGE plpgsql;

SELECT c.*, g.*
FROM getngrams('packages/hooks/src/createRunHook.js',12,0,71,1,2::smallint) as g,
     calls c
WHERE 'gutenberg' = c.origin
AND c.session = g.session
AND line >= g.left
AND line < g.left+g.n
ORDER BY g.n, g.hash,g.session,c.line;

--EXPLAIN (ANALYZE, BUFFERS) 
SELECT c.*, g.*
FROM getngrams('packages/hooks/src/createDoingHook.js',10,0,30,1,2::smallint) as g,
     calls c
WHERE 'gutenberg' = c.origin
AND c.session = g.session
AND line >= g.left
AND line < g.left+g.n
ORDER BY g.n, g.hash,g.session,c.line;


  SELECT origin, path, sl, sc, el, ec,
  SUM((SIGN(session)>0)::int) as pocc,
  SUM((SIGN(session)<0)::int) as tocc
  FROM calls c
  WHERE origin = 'gutenberg'
  AND path ~ 'packages.blocks.src.*'
  GROUP BY origin, path, sl, sc, el, ec;

WITH initPaths AS (
  SELECT origin, path, sl, sc, el, ec
  FROM calls c
  WHERE origin = 'gutenberg'
  AND path ~ 'packages.blocks.src.api.registrationÃ§0js'
  GROUP BY origin, path, sl, sc, el, ec
)
SELECT g.n, g.hash, g.pocc, g.tocc
FROM initPaths i, LATERAL getngrams(formatPath(i.path),i.sl,i.sc,i.el,i.ec,2::smallint) as g;
#+END_SRC
#+NAME: just forwarding the shift
#+BEGIN_SRC sql
DROP FUNCTION public.getngrams;
--DELETE FROM acctable;DELETE FROM grouptable;
CREATE OR REPLACE FUNCTION public.compute2gram(initPath text, sl int, sc int, el int, ec int)
 RETURNS void AS $BODY$
#variable_conflict use_variable
DECLARE
  origin text;
BEGIN
  origin:='gutenberg';

  WITH a1 AS (
    -- get 1-grams of initPath:sl:sc:el:ec
    SELECT MD5(CONCAT(formatPath(c.path),c.sl,c.sc,c.el,c.ec)) as hash,
           c.session as session, c.line as "left"
    FROM CALLS c
    WHERE origin = c.origin
    AND path @> formatPath(initPath)
    AND sl = c.sl
    AND sc = c.sc
    AND el = c.el
    AND ec = c.ec
  ), g1 AS (
    -- Procedure to instanciate statics of 1-gram in groupTable
    INSERT INTO groupTable (origin, path, sl, sc, el, ec, n, hash, shift, pocc, tocc)
    SELECT origin, formatPath(initPath), sl, sc, el, ec, 1, a.hash, 0,
           SUM((SIGN(a.session)>0)::int),
           SUM((SIGN(a.session)<0)::int)
    FROM a1 a
    GROUP BY a.hash
    ON CONFLICT ON CONSTRAINT grouptable_pkey
    DO UPDATE SET pocc = excluded.pocc, tocc = excluded.tocc
    RETURNING pocc, tocc
  ), a2 AS (
    INSERT INTO accTable (origin, n, hash, session, "left", isLastPrev, shift)
    -- move to previous line, n=2
    SELECT origin, 2, MD5(CONCAT(formatPath(c.path),c.sl,c.sc,c.el,c.ec,MD5(CONCAT(formatPath(initPath),sl,sc,el,ec)))) as hash2,
    a.session, a."left"-1, true, 1
    FROM a1 a, g1 g, calls c
    WHERE origin = c.origin
    AND a.session = c.session
    AND a.left-1 = c.line 
    AND NOT (
        formatPath(initPath) <@ c.path
        AND sl = c.sl
        AND sc = c.sc
        AND el = c.el
        AND ec = c.ec)
    UNION ALL
    -- move to next line, n=2
    SELECT origin, 2, MD5(CONCAT(MD5(CONCAT(formatPath(initPath),sl,sc,el,ec)),formatPath(c.path),c.sl,c.sc,c.el,c.ec)) as hash2,
    a.session, a.left, false, 0
    FROM a1 a, g1 g, calls c
    WHERE origin = c.origin
    AND a.session = c.session
    AND a.left+(2-1) = c.line
      ON CONFLICT ON CONSTRAINT acctable_pkey
      DO UPDATE
      SET hash = accTable.hash, shift = excluded.shift --LEAST(excluded.shift,accTable.shift)
      --need to update group table  (change hash)
    RETURNING acctable.hash, acctable.session, acctable.shift
  )
  INSERT INTO groupTable (origin, path, sl, sc, el, ec, n, hash, shift, pocc, tocc)
  SELECT origin, formatPath(initPath), sl, sc, el, ec, 2 as n, a.hash, MIN(a.shift),
         SUM((SIGN(a.session)>0)::int),
         SUM((SIGN(a.session)<0)::int)
  FROM a2 a
  WHERE NOT a.hash is NULL
  GROUP BY a.hash
  ON CONFLICT ON CONSTRAINT grouptable_pkey 
  DO UPDATE SET pocc = excluded.pocc, tocc = excluded.tocc;

END;
$BODY$ LANGUAGE plpgsql;

CREATE OR REPLACE FUNCTION public.getngrams(initPath text, sl int, sc int, el int, ec int, max_n smallint)
 RETURNS TABLE(n int, hash text, session int, left int, pocc bigint, tocc bigint, shift smallint) AS $BODY$
#variable_conflict use_variable
DECLARE
  origin text;
  checkpoint_n smallint;
BEGIN
  origin:='gutenberg';
  checkpoint_n := (
    select MAX(g.n)
    from groupTable g
    where origin = g.origin
    AND g.path @> formatPath(initPath)
    AND sl = g.sl
    AND sc = g.sc
    AND el = g.el
    AND ec = g.ec
    GROUP BY g.path, g.sl, g.sc, g.el, g.ec
  );
  IF checkpoint_n is NULL
  THEN
    PERFORM compute2gram(initPath, sl, sc, el, ec);
  END IF;

  RETURN QUERY SELECT g.n, g.hash, a.session, a.left, g.pocc, g.tocc, g.shift
  FROM   groupTable g
  CROSS  JOIN LATERAL (
  SELECT a.session, a.left
  FROM   accTable a, calls c
  WHERE 
    g.path @> formatPath(initPath)
    AND sl = g.sl
    AND sc = g.sc
    AND el = g.el
    AND ec = g.ec
    AND g.n = a.n AND g.hash = a.hash         -- lateral reference
  --ORDER BY c.session, c.line
  LIMIT  1
  ) a
  UNION ALL
  SELECT g.n, g.hash, a.session, a.left, g.pocc, g.tocc, g.shift
  FROM   groupTable g
  CROSS  JOIN LATERAL (
  SELECT c.session as session, c.line as "left"
    FROM CALLS c
    WHERE g.n=1
    AND g.path @> formatPath(initPath)
    AND sl = g.sl    AND sc = g.sc    AND el = g.el    AND ec = g.ec
    AND origin = c.origin
    AND c.path @> formatPath(initPath)
    AND sl = c.sl    AND sc = c.sc    AND el = c.el    AND ec = c.ec
    --ORDER BY c.session, c.line
    LIMIT 1) a;
END;
$BODY$ LANGUAGE plpgsql;

SELECT c.*, g.*
FROM getngrams('packages/hooks/src/createRunHook.js',12,0,71,1,2::smallint) as g,
     calls c
WHERE 'gutenberg' = c.origin
AND c.session = g.session
AND line >= g.left
AND line < g.left+g.n
ORDER BY g.n, g.hash,g.session,c.line;

--EXPLAIN (ANALYZE, BUFFERS) 
SELECT c.*, g.*
FROM getngrams('packages/hooks/src/createDoingHook.js',10,0,30,1,2::smallint) as g,
     calls c
WHERE 'gutenberg' = c.origin
AND c.session = g.session
AND line >= g.left
AND line < g.left+g.n
ORDER BY g.n, g.hash,g.session,c.line;


  SELECT origin, path, sl, sc, el, ec,
  SUM((SIGN(session)>0)::int) as pocc,
  SUM((SIGN(session)<0)::int) as tocc
  FROM calls c
  WHERE origin = 'gutenberg'
  AND path ~ 'packages.blocks.src.*'
  GROUP BY origin, path, sl, sc, el, ec;

WITH initPaths AS (
  SELECT origin, path, sl, sc, el, ec
  FROM calls c
  WHERE origin = 'gutenberg'
  AND path ~ 'packages.blocks.src.api.registrationÃ§0js'
  GROUP BY origin, path, sl, sc, el, ec
)
SELECT g.n, g.hash, g.pocc, g.tocc
FROM initPaths i, LATERAL getngrams(formatPath(i.path),i.sl,i.sc,i.el,i.ec,2::smallint) as g;
#+END_SRC
** [2019-06-29 Sat]
*** TODO see http://smlab.cs.tau.ac.il/xlog/lc-ase14.pdf with benoit
* Emacs Settings                                                   :noexport:
#    (ox-extras-activate '(ignore-headlines))
Local Variables:
eval:    (setq org-confirm-babel-evaluate nil)
eval:    (org-babel-do-load-languages 'org-babel-load-languages '( (shell . t) (R . t) (perl . t) (ditaa . t) ))
eval:    (setq org-latex-listings 'minted)
eval:    (add-to-list 'org-latex-packages-alist '("" "minted"))
eval:    (setq org-src-fontify-natively t)
eval:    (setq org-image-actual-width '(600))
eval:    (unless (boundp 'org-latex-classes) (setq org-latex-classes nil))
eval:    (setq org-latex-with-hyperref nil)
eval:    (add-to-list 'org-latex-classes '("llncs" "\\documentclass{llncs}\n \[NO-DEFAULT-PACKAGES]\n \[EXTRA]\n"  ("\\section{%s}" . "\\section*{%s}") ("\\subsection{%s}" . "\\subsection*{%s}")                       ("\\subsubsection{%s}" . "\\subsubsection*{%s}")                       ("\\paragraph{%s}" . "\\paragraph*{%s}")                       ("\\subparagraph{%s}" . "\\subparagraph*{%s}")))
eval:    (setq org-latex-pdf-process (list "latexmk -bibtex -shell-escape -f -pdf %F"))
End:
